Metadata-Version: 2.1
Name: rai_toolbox
Version: 0.2.1
Summary: PyTorch-centric library for evaluating and enhancing the robustness of AI technologies
Home-page: https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox
Author: Ryan Soklaski, Justin Goodwin, Olivia Brown, Michael Yee
Author-email: ryan.soklaski@ll.mit.edu
License: MIT
Download-URL: https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox/tarball/v0.2.1
Keywords: machine learning robustness pytorch responsible AI
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Topic :: Scientific/Engineering
Requires-Python: >=3.7
Provides-Extra: tests
Provides-Extra: mushin
License-File: LICENSE.txt


The rAI-toolbox is designed to enable methods for evaluating and enhancing both the
robustness and the explainability of AI models in a way that is scalable and that
composes naturally with other popular ML frameworks.

A key design principle of the rAI-toolbox is that it adheres strictly to the APIs
specified by the PyTorch machine learning framework. For example, the rAI-toolbox frames
adversarial training workflows solely in terms of the `torch.nn.Optimizer` and
`torch.nn.Module` APIs. This makes it trivial to leverage other libraries and
frameworks from the PyTorch ecosystem to bolster your responsible AI R&D. For
instance, one can naturally leverage the rAI-toolbox together with
PyTorch Lightning to perform distributed adversarial training.


