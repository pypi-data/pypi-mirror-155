import gft
# https://github.com/PaddlePaddle/ERNIE/blob/develop/README.en.md

# There seem to be two model zoos there
# We are currently using paddle_model_zoo,
# but many of these do not load

# https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers.html
# https://github.com/PaddlePaddle/PaddleNLP/tree/develop/paddlenlp/transformers

# paddlenlp_model_zoo = ["albert",
#                        "auto",
#                        "bart",
#                        "bert",
#                        "bert_japanese",
#                        "bigbird",
#                        "blenderbot",
#                        "blenderbot_small",
#                        "chinesebert",
#                        "convbert",
#                        "ctrl",
#                        "distilbert",
#                        "electra",
#                        "ernie",
#                        "ernie_ctm",
#                        "ernie_doc",
#                        "ernie_gen",
#                        "ernie_gram",
#                        "ernie_m",
#                        "fnet",
#                        "funnel",
#                        "gpt",
#                        # "layoutlm",
#                        # "layoutlmv2",
#                        # "layoutxlm",
#                        "luke",
#                        "mbart",
#                        "megatronbert",
#                        "mobilebert",
#                        "mpnet",
#                        "nezha",
#                        "ppminilm",
#                        "prophetnet",
#                        "reformer",
#                        "roberta",
#                        "roformer",
#                        "semantic_indexing",
#                        "skep",
#                        "squeezebert",
#                        "t5",
#                        "tinybert",
#                        "transformer",
#                        "unified_transformer",
#                        "unimo",
#                        "xlnet"]

old_paddle_model_zoo = ["albert-base-v1",
                    "albert-base-v2",
                    "albert-chinese-base",
                    "albert-chinese-large",
                    "albert-chinese-small",
                    "albert-chinese-tiny",
                    "albert-chinese-xlarge",
                    "albert-chinese-xxlarge",
                    "albert-large-v1",
                    "albert-large-v2",
                    "albert-xlarge-v1",
                    "albert-xlarge-v2",
                    "albert-xxlarge-v1",
                    "albert-xxlarge-v2",
                    # "BART",
                    "bart-base",
                    "bart-large",
                    # "BERT",
                    "bert-base-cased",
                    "bert-base-chinese",
                    "bert-base-multilingual-cased",
                    "bert-base-multilingual-uncased",
                    "bert-base-uncased",
                    # "BERT-Japanese",
                    "bert-large-cased",
                    "bert-large-uncased",
                    "bert-wwm-chinese",
                    "bert-wwm-ext-chinese",
                    # "BigBird",
                    "bigbird-base-uncased",
                    # "Blenderbot",
                    "blenderbot-1B-distill",
                    "blenderbot-3B",
                    "blenderbot-400M-distill",
                    # "Blenderbot-Small",
                    "blenderbot_small-90M",
                    "chinese-electra-base",
                    "chinese-electra-small",
                    "chinese-xlnet-base",
                    "chinese-xlnet-large",
                    "chinese-xlnet-mid",
                    # "ConvBert",
                    "convbert-base",
                    "convbert-medium-small",
                    "convbert-small",
                    "ctrl",
                    # "CTRL",
                    # "DistilBert",
                    "distilbert-base-cased",
                    "distilbert-base-multilingual-cased",
                    "distilbert-base-uncased",
                    # "ELECTRA",
                    "electra-base",
                    "electra-large",
                    "electra-small",
                    # "ERNIE",
                    "ernie-1.0",
                    "ernie-2.0-en",
                    "ernie-2.0-en-finetuned-squad",
                    # "ernie-2.0-large-en",
                    # "ERNIE-DOC",
                    "ernie-doc-base-en",
                    "ernie-doc-base-zh",
                    # "ERNIE-GEN",
                    "ernie-gen-base-en",
                    "ernie-gen-large-en",
                    "ernie-gen-large-en-430g",
                    # "ERNIE-GRAM",
                    "ernie-gram-zh",
                    "ernie-tiny",
                    # "GPT",
                    "gpt2-en",
                    "gpt2-large-en",
                    "gpt2-medium-en",
                    "gpt2-xl-en",
                    "gpt-cpm-large-cn",
                    "gpt-cpm-small-cn-distill",
                    "iverxin/bert-base-japanese",
                    "iverxin/bert-base-japanese-char",
                    "iverxin/bert-base-japanese-char-whole-word-masking",
                    "iverxin/bert-base-japanese-whole-word-masking",
                    "junnyu/ckiplab-bert-base-chinese-ner",
                    "junnyu/ckiplab-bert-base-chinese-pos",
                    "junnyu/ckiplab-bert-base-chinese-ws",
                    "junnyu/distilgpt2",
                    "junnyu/hfl-chinese-electra-180g-base-discriminator",
                    "junnyu/hfl-chinese-electra-180g-small-ex-discriminator",
                    "junnyu/hfl-chinese-legal-electra-small-generator",
                    "junnyu/microsoft-DialoGPT-large",
                    "junnyu/microsoft-DialoGPT-medium",
                    "junnyu/microsoft-DialoGPT-small",
                    "junnyu/nlptown-bert-base-multilingual-uncased-sentiment",
                    "junnyu/tbs17-MathBERT",
                    "junnyu/uer-gpt2-chinese-poem",
                    "Langboat/mengzi-bert-base",
                    "Langboat/mengzi-bert-base-fin",
                    # "LayoutLM",
                    "layoutlm-base-uncased",
                    "layoutlm-large-uncased",
                    # "LayoutLMV2",
                    "layoutlmv2-base-uncased",
                    "layoutlmv2-large-uncased",
                    # "LayoutXLM",
                    "layoutxlm-base-uncased",
                    "macbert-base-chinese",
                    "macbert-large-chinese",
                    # "MBart",
                    "mbart-large-50-many-to-many-mmt",
                    "mbart-large-50-many-to-one-mmt",
                    "mbart-large-50-one-to-many-mmt",
                    "mbart-large-cc25",
                    "mbart-large-en-ro",
                    # "Mobilebert",
                    "mobilebert-uncased",
                    # "MPNet",
                    "mpnet-base",
                    # "NeZha",
                    "nezha-base-chinese",
                    "nezha-base-wwm-chinese",
                    "nezha-large-chinese",
                    "nezha-large-wwm-chinese",
                    "nosaydomore/deepset-roberta-base-squad2",
                    "nosaydomore/roberta-en-base",
                    "nosaydomore/roberta-en-large",
                    "nosaydomore/sshleifei-tiny-distilroberta-base",
                    "nosaydomore/uer-roberta-base-chn-extractive-qa",
                    "nosaydomore/uer-roberta-base-ft-chinanews-chn",
                    "nosaydomore/uer-roberta-base-ft-cluener2020-chn",
                    "plato-mini",
                    "rbt3",
                    "rbtl3",
                    # "Reformer",
                    "reformer-crime-and-punishment",
                    "reformer-enwik8",
                    # "RoBERTa",
                    "roberta-wwm-ext",
                    "roberta-wwm-ext-large",
                    # "RoFormer",
                    "roformer-chinese-base",
                    "roformer-chinese-char-base",
                    "roformer-chinese-char-small",
                    "roformer-chinese-sim-char-base",
                    "roformer-chinese-sim-char-ft-base",
                    "roformer-chinese-sim-char-ft-small",
                    "roformer-chinese-sim-char-small",
                    "roformer-chinese-small",
                    "roformer-english-small-discriminator",
                    "roformer-english-small-generator",
                    "simbert-base-chinese",
                    # "SKEP",
                    "skep_ernie_1.0_large_ch",
                    "skep_ernie_2.0_large_en",
                    "skep_roberta_large_en",
                    # "SqueezeBert",
                    "squeezebert-mnli",
                    "squeezebert-mnli-headless",
                    "squeezebert-uncased",
                    "sshleifer-tiny-ctrl",
                    "sshleifer-tiny-distilbert-base-uncase-finetuned-sst-2-english",
                    # "T5",
                    "t5-base",
                    "t5-large",
                    "t5-small",
                    # "TinyBert",
                    "tinybert-4l-312d",
                    "tinybert-4l-312d-v2",
                    "tinybert-4l-312d-zh",
                    "tinybert-6l-768d",
                    "tinybert-6l-768d-v2",
                    "tinybert-6l-768d-zh",
                    # "UnifiedTransformer",
                    "unified_transformer-12L-cn",
                    "unified_transformer-12L-cn-luge",
                    # "UNIMO",
                    "unimo-text-1.0",
                    "unimo-text-1.0-large",
                    "unimo-text-1.0-lcsts-new",
                    # "XLNet",
                    "xlnet-base-cased",
                    "xlnet-large-cased"]

paddle_model_zoo = ["bert-base-uncased",
                    "cross-encoder/ms-marco-MiniLM-L-12-v2",
                    "cl-tohoku/bert-base-japanese-char",
                    "bert-base-chinese",
                    "bert-base-cased",
                    "cl-tohoku/bert-base-japanese-whole-word-masking",
                    "cl-tohoku/bert-base-japanese",
                    "bert-base-multilingual-cased",
                    "nlptown/bert-base-multilingual-uncased-sentiment",
                    "bert-large-uncased-whole-word-masking-finetuned-squad",
                    "finiteautomata/beto-sentiment-analysis",
                    "hfl/chinese-bert-wwm-ext",
                    "bert-large-uncased",
                    "bert-base-multilingual-uncased",
                    "emilyalsentzer/Bio_ClinicalBERT",
                    "dslim/bert-base-NER",
                    "deepset/bert-large-uncased-whole-word-masking-squad2",
                    "neuralmind/bert-base-portuguese-cased",
                    "bert-large-cased",
                    "SpanBERT/spanbert-large-cased",
                    "dslim/bert-large-NER",
                    "bert-base-german-cased",
                    "deepset/sentence_bert",
                    "ProsusAI/finbert",
                    "oliverguhr/german-sentiment-bert",
                    "google/bert_uncased_L-2_H-128_A-2",
                    "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract",
                    "DeepPavlov/rubert-base-cased",
                    "wietsedv/bert-base-dutch-cased",
                    "monologg/bert-base-cased-goemotions-original",
                    "allenai/scibert_scivocab_uncased",
                    "dbmdz/bert-large-cased-finetuned-conll03-english",
                    "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext",
                    "bert-large-uncased-whole-word-masking",
                    "dccuchile/bert-base-spanish-wwm-uncased",
                    "google/bert_uncased_L-6_H-256_A-4",
                    "google/bert_uncased_L-4_H-512_A-8",
                    "FPTAI/vibert-base-cased",
                    "cointegrated/rubert-tiny",
                    "bert-base-german-dbmdz-uncased",
                    "dbmdz/bert-base-turkish-128k-cased",
                    "dbmdz/bert-base-german-uncased",
                    "deepset/minilm-uncased-squad2",
                    "HooshvareLab/bert-base-parsbert-uncased",
                    "textattack/bert-base-uncased-ag-news",
                    "cl-tohoku/bert-base-japanese-v2",
                    "emilyalsentzer/Bio_Discharge_Summary_BERT",
                    "KoichiYasuoka/bert-base-japanese-upos",
                    "dbmdz/bert-base-italian-xxl-cased",
                    "deepset/bert-base-cased-squad2",
                    "beomi/kcbert-large",
                    "bert-large-cased-whole-word-masking-finetuned-squad",
                    "neuralmind/bert-large-portuguese-cased",
                    "Luyu/co-condenser-marco",
                    "Sahajtomar/German_Zeroshot",
                    "indolem/indobert-base-uncased",
                    "shibing624/text2vec-base-chinese",
                    "cointegrated/LaBSE-en-ru",
                    "prithivida/parrot_fluency_on_BERT",
                    "textattack/bert-base-uncased-SST-2",
                    "textattack/bert-base-uncased-snli",
                    "klue/bert-base",
                    "asafaya/bert-base-arabic",
                    "textattack/bert-base-uncased-MRPC",
                    "textattack/bert-base-uncased-imdb",
                    "cross-encoder/ms-marco-TinyBERT-L-2",
                    "mrm8488/bert-tiny-finetuned-sms-spam-detection",
                    "felflare/bert-restore-punctuation",
                    "sshleifer/tiny-dbmdz-bert-large-cased-finetuned-conll03-english",
                    "textattack/bert-base-uncased-rotten-tomatoes",
                    "textattack/bert-base-uncased-rotten_tomatoes",
                    "nlpaueb/legal-bert-base-uncased",
                    "hf-internal-testing/tiny-bert-for-token-classification",
                    "cointegrated/rubert-tiny2",
                    "kykim/bert-kor-base",
                    "cl-tohoku/bert-base-japanese-char-v2",
                    "mrm8488/bert-small-finetuned-squadv2",
                    "beomi/kcbert-base",
                    "textattack/bert-base-uncased-MNLI",
                    "textattack/bert-base-uncased-WNLI",
                    "dbmdz/bert-base-turkish-cased",
                    "huawei-noah/TinyBERT_General_4L_312D",
                    "textattack/bert-base-uncased-QQP",
                    "textattack/bert-base-uncased-STS-B",
                    "allenai/scibert_scivocab_cased",
                    "mrm8488/bert-medium-finetuned-squadv2",
                    "TurkuNLP/bert-base-finnish-cased-v1",
                    "textattack/bert-base-uncased-RTE",
                    "uer/roberta-base-chinese-extractive-qa",
                    "textattack/bert-base-uncased-QNLI",
                    "textattack/bert-base-uncased-CoLA",
                    "dmis-lab/biobert-base-cased-v1.2",
                    "pierreguillou/bert-base-cased-squad-v1.1-portuguese",
                    "KB/bert-base-swedish-cased",
                    "uer/roberta-base-finetuned-cluener2020-chinese",
                    "onlplab/alephbert-base",
                    "mrm8488/bert-spanish-cased-finetuned-ner",
                    "alvaroalon2/biobert_chemical_ner",
                    "bert-base-cased-finetuned-mrpc",
                    "unitary/toxic-bert",
                    "nlpaueb/bert-base-greek-uncased-v1",
                    "HooshvareLab/bert-fa-base-uncased-sentiment-snappfood",
                    "Maltehb/danish-bert-botxo",
                    "shahrukhx01/bert-mini-finetune-question-detection",
                    "GroNLP/bert-base-dutch-cased",
                    "SpanBERT/spanbert-base-cased",
                    "dbmdz/bert-base-italian-uncased",
                    "dbmdz/bert-base-german-cased",
                    "cl-tohoku/bert-large-japanese",
                    "hfl/chinese-bert-wwm",
                    "hfl/chinese-macbert-large",
                    "dslim/bert-base-NER-uncased",
                    "amberoad/bert-multilingual-passage-reranking-msmarco",
                    "aubmindlab/bert-base-arabertv02",
                    "google/bert_uncased_L-4_H-256_A-4",
                    "DeepPavlov/rubert-base-cased-conversational",
                    "dccuchile/bert-base-spanish-wwm-cased",
                    "ckiplab/bert-base-chinese-ws",
                    "daigo/bert-base-japanese-sentiment",
                    "SZTAKI-HLT/hubert-base-cc",
                    "nlpaueb/legal-bert-small-uncased",
                    "dumitrescustefan/bert-base-romanian-uncased-v1",
                    "google/muril-base-cased",
                    "dkleczek/bert-base-polish-uncased-v1",
                    "ckiplab/bert-base-chinese-ner",
                    "savasy/bert-base-turkish-sentiment-cased",
                    "mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es",
                    "KB/bert-base-swedish-cased-ner",
                    "hfl/rbt3",
                    "remotejob/gradientclassification_v0",
                    "Recognai/bert-base-spanish-wwm-cased-xnli",
                    "HooshvareLab/bert-fa-zwnj-base",
                    "blanchefort/rubert-base-cased-sentiment",
                    "monologg/bert-base-cased-goemotions-group",
                    "shibing624/macbert4csc-base-chinese",
                    "google/bert_uncased_L-8_H-512_A-8",
                    "bert-large-cased-whole-word-masking",
                    "alvaroalon2/biobert_diseases_ner",
                    "philschmid/BERT-Banking77",
                    "dbmdz/bert-base-turkish-uncased",
                    "vblagoje/bert-english-uncased-finetuned-pos",
                    "dumitrescustefan/bert-base-romanian-cased-v1",
                    "nreimers/BERT-Tiny_L-2_H-128_A-2",
                    "digitalepidemiologylab/covid-twitter-bert-v2",
                    "UBC-NLP/MARBERT",
                    "pierreguillou/bert-large-cased-squad-v1.1-portuguese",
                    "alvaroalon2/biobert_genetic_ner",
                    "bvanaken/clinical-assertion-negation-bert",
                    "cross-encoder/stsb-TinyBERT-L-4",
                    "sshleifer/tiny-distilbert-base-cased",
                    "ckiplab/bert-base-chinese",
                    "fabriceyhc/bert-base-uncased-amazon_polarity",
                    "roberta-base",
                    "cardiffnlp/twitter-roberta-base-sentiment",
                    "deepset/roberta-base-squad2",
                    "roberta-large",
                    "distilroberta-base",
                    "cross-encoder/nli-distilroberta-base",
                    "siebert/sentiment-roberta-large-english",
                    "j-hartmann/emotion-english-distilroberta-base",
                    "roberta-base-openai-detector",
                    "huggingface/CodeBERTa-small-v1",
                    "mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis",
                    "cardiffnlp/twitter-roberta-base-emotion",
                    "seyonec/PubChem10M_SMILES_BPE_396_250",
                    "textattack/roberta-base-SST-2",
                    "sshleifer/tiny-distilroberta-base",
                    "thatdramebaazguy/roberta-base-squad",
                    "ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli",
                    "ufal/robeczech-base",
                    "seyonec/PubChem10M_SMILES_BPE_450k",
                    "cardiffnlp/twitter-roberta-base",
                    "seyonec/PubChem10M_SMILES_BPE_50k",
                    "microsoft/codebert-base-mlm",
                    "textattack/roberta-base-MNLI",
                    "cardiffnlp/twitter-roberta-base-offensive",
                    "cross-encoder/stsb-roberta-large",
                    "seyonec/ChemBERTa_zinc250k_v2_40k",
                    "uklfr/gottbert-base",
                    "seyonec/ChemBERTa-zinc-base-v1",
                    "roberta-large-openai-detector",
                    "cross-encoder/quora-roberta-base",
                    "cross-encoder/stsb-roberta-base",
                    "microsoft/graphcodebert-base",
                    "cardiffnlp/twitter-roberta-base-hate",
                    "chkla/roberta-argument",
                    "Salesforce/grappa_large_jnt",
                    "vinai/bertweet-large",
                    "allenai/biomed_roberta_base",
                    "facebook/muppet-roberta-base",
                    "Rakib/roberta-base-on-cuad",
                    "cross-encoder/stsb-distilroberta-base",
                    "nyu-mll/roberta-base-1B-1",
                    "nyu-mll/roberta-med-small-1M-1",
                    "SkolkovoInstitute/roberta_toxicity_classifier",
                    "facebook/muppet-roberta-large",
                    "lassl/roberta-ko-small",
                    "huggingface/CodeBERTa-language-id",
                    "textattack/roberta-base-imdb",
                    "macedonizer/mk-roberta-base",
                    "cross-encoder/nli-MiniLM2-L6-H768",
                    "textattack/roberta-base-QNLI",
                    "deepset/roberta-base-squad2-covid",
                    "textattack/roberta-base-MRPC",
                    "bhadresh-savani/roberta-base-emotion",
                    "aychang/roberta-base-imdb",
                    "cross-encoder/quora-distilroberta-base",
                    "csarron/roberta-base-squad-v1",
                    "seyonec/ChemBERTA_PubChem1M_shard00_155k",
                    "mental/mental-roberta-base",
                    "textattack/roberta-base-CoLA",
                    "navteca/quora-roberta-base",
                    "cardiffnlp/twitter-roberta-base-emoji",
                    "benjamin/roberta-base-wechsel-german",
                    "textattack/roberta-base-ag-news",
                    "johngiorgi/declutr-base",
                    "salesken/query_wellformedness_score",
                    "blinoff/roberta-base-russian-v0",
                    "allenai/reviews_roberta_base",
                    "ruiqi-zhong/roberta-base-meta-tuning-test",
                    "mrm8488/distilroberta-finetuned-tweets-hate-speech",
                    "cointegrated/roberta-large-cola-krishna2020",
                    "deepset/roberta-base-squad2-distilled",
                    "tli8hf/unqover-roberta-base-squad",
                    "cross-encoder/nli-roberta-base",
                    "nreimers/MiniLMv2-L6-H384-distilled-from-RoBERTa-Large",
                    "seyonec/BPE_SELFIES_PubChem_shard00_160k",
                    "CLTL/MedRoBERTa.nl",
                    "HooshvareLab/roberta-fa-zwnj-base",
                    "nyu-mll/roberta-base-100M-1",
                    "deepset/tinyroberta-squad2",
                    "youscan/ukr-roberta-base",
                    "navteca/roberta-base-squad2",
                    "bertin-project/bertin-roberta-base-spanish",
                    "shiyue/roberta-large-tac08",
                    "softcatala/julibert",
                    "elozano/tweet_sentiment_eval",
                    "cahya/roberta-base-indonesian-1.5G",
                    "elozano/tweet_emotion_eval",
                    "navteca/roberta-large-squad2",
                    "elozano/tweet_offensive_eval",
                    "ynie/roberta-large_conv_contradiction_detector_v0",
                    "distilgpt2",
                    "w11wo/javanese-gpt2-small-imdb",
                    "remotejob/tweetsDISTILGPT2fi_v4",
                    "TrLOX/gpt2-tdk",
                    "huggingtweets/slime_machine",
                    "microsoft/DialoGPT-small",
                    "sberbank-ai/rugpt3large_based_on_gpt2",
                    "sshleifer/tiny-gpt2",
                    "microsoft/DialoGPT-large",
                    "sberbank-ai/rugpt3small_based_on_gpt2",
                    "uw-hai/polyjuice",
                    "NYTK/text-generation-poem-petofi-gpt2-small-hungarian",
                    "microsoft/DialogRPT-human-vs-rand",
                    "hf-internal-testing/tiny-random-gpt2",
                    "Grossmend/rudialogpt3_medium_based_on_gpt2",
                    "pranavpsv/genre-story-generator-v2",
                    "microsoft/DialogRPT-updown",
                    "microsoft/DialogRPT-human-vs-machine",
                    "pierreguillou/gpt2-small-portuguese",
                    "mrm8488/GPT-2-finetuned-covid-bio-medrxiv",
                    "anonymous-german-nlp/german-gpt2",
                    "microsoft/CodeGPT-small-py",
                    "antoiloui/belgpt2",
                    "benjamin/gerpt2",
                    "asi/gpt-fr-cased-small",
                    "microsoft/CodeGPT-small-java-adaptedGPT2",
                    "GroNLP/gpt2-small-dutch",
                    "lvwerra/gpt2-imdb",
                    "DeepESP/gpt2-spanish",
                    "microsoft/CodeGPT-small-py-adaptedGPT2",
                    "microsoft/DialogRPT-width",
                    "dbddv01/gpt2-french-small",
                    "GroNLP/gpt2-small-italian",
                    "flax-community/gpt2-medium-persian",
                    "microsoft/DialogRPT-depth",
                    "Nokia/nlgp-natural",
                    "macedonizer/hr-gpt2",
                    "mrm8488/GPT-2-finetuned-common_gen",
                    "pranavpsv/gpt2-genre-story-generator",
                    "rbhushan/distilgpt2-finetuned-wikitext2",
                    "readerbench/RoGPT2-large",
                    "flax-community/gpt2-small-indonesian",
                    "HooshvareLab/gpt2-fa",
                    "cahya/gpt2-small-indonesian-522M",
                    "DingleyMaillotUrgell/homer-bot",
                    "datificate/gpt2-small-spanish",
                    "ericzhou/tsundere_v1",
                    "huggingtweets/wwm_shakespeare",
                    "SIC98/GPT2-python-code-generator",
                    "GroNLP/gpt2-small-italian-embeddings",
                    "huggingtweets/hel_ql-shahdashrf_-sinnerslayerr-witheredstrings",
                    "salesken/grammar_correction",
                    "flax-community/gpt2-medium-indonesian",
                    "gorkemgoknar/gpt2-small-turkish",
                    "deepparag/DumBot",
                    "jcblaise/gpt2-tagalog",
                    "BigSalmon/InformalToFormalLincoln21",
                    "LorenzoDeMattei/GePpeTto",
                    "macedonizer/sr-gpt2",
                    "indonesian-nlp/gpt2",
                    "ceostroff/harry-potter-gpt2-fanfiction",
                    "akhooli/gpt2-small-arabic-poetry",
                    "asi/gpt-fr-cased-base",
                    "congcongwang/gpt2_medium_fine_tuned_coder",
                    "cambridgeltl/simctg_wikitext103",
                    "t5-small",
                    "t5-base",
                    "deep-learning-analytics/wikihow-t5-small",
                    "sberbank-ai/ruT5-base",
                    "t5-large",
                    "Michau/t5-base-en-generate-headline",
                    "google/t5-v1_1-large",
                    "google/t5-v1_1-small",
                    "prithivida/parrot_paraphraser_on_T5",
                    "prithivida/grammar_error_correcter_v1",
                    "valhalla/t5-small-qg-hl",
                    "valhalla/t5-small-qa-qg-hl",
                    "google/t5-v1_1-base",
                    "ramsrigouthamg/t5-large-paraphraser-diverse-high-quality",
                    "mrm8488/t5-base-finetuned-common_gen",
                    "valhalla/t5-small-e2e-qg",
                    "sonoisa/t5-base-japanese",
                    "google/t5-base-lm-adapt",
                    "google/t5-small-lm-adapt",
                    "valhalla/t5-small-qg-prepend",
                    "prithivida/informal_to_formal_styletransfer",
                    "KETI-AIR/ke-t5-base",
                    "nielsr/nt5-small-rc1",
                    "snrspeaks/t5-one-line-summary",
                    "mrm8488/t5-small-finetuned-quora-for-paraphrasing",
                    "Langboat/mengzi-t5-base",
                    "p-christ/12412fsasf",
                    "tscholak/3vnuv1vf",
                    "tennessejoyce/titlewave-t5-base",
                    "vennify/t5-base-grammar-correction",
                    "google/t5-large-ssm",
                    "megagonlabs/t5-base-japanese-web",
                    "sberbank-ai/ruT5-large",
                    "tscholak/t5.1.1.lm100k.base",
                    "deep-learning-analytics/GrammarCorrector",
                    "ThomasNLG/t5-qa_squad2neg-en",
                    "flexudy/t5-small-wav2vec2-grammar-fixer",
                    "KETI-AIR/ke-t5-small",
                    "razent/SciFive-large-Pubmed_PMC",
                    "google/t5-large-ssm-nq",
                    "ozcangundes/T5-base-for-BioQA",
                    "Rostlab/prot_t5_base_mt_uniref50",
                    "sonoisa/t5-base-japanese-question-generation",
                    "Wikidepia/IndoT5-base",
                    "razent/SciFive-base-Pubmed_PMC",
                    "google/t5-small-ssm-nq",]
