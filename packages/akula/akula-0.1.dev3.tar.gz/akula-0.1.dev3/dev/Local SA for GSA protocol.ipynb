{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "import bw2calc as bc\n",
    "import bw_processing as bwp\n",
    "from pypardiso import spsolve\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from gsa_framework.utils import read_pickle, write_pickle\n",
    "from fs.zipfs import ZipFS\n",
    "import sys\n",
    "sys.path.append('/Users/akim/PycharmProjects/akula')\n",
    "\n",
    "# Local files\n",
    "from akula.sensitivity_analysis.local_sa import *\n",
    "\n",
    "project = 'GSA for archetypes'\n",
    "bd.projects.set_current(project)\n",
    "const_factor = 10\n",
    "cutoff = 1e-6  # For contribution analysis\n",
    "max_calc = 1e16  # For supply chain traversal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4861703",
   "metadata": {},
   "source": [
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47aef7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "co = bd.Database('swiss consumption 1.0')\n",
    "fu = [act for act in co if \"ch hh average consumption aggregated, years 151617\" == act['name']][0]\n",
    "\n",
    "write_dir = Path(\"write_files\") / project.lower().replace(\" \", \"_\") / fu['name'].lower().replace(\" \", \"_\").replace(\",\", \"\")\n",
    "write_dir_sct = write_dir / \"supply_chain_traversal\" \n",
    "write_dir_sct.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "demand = {fu: 1}\n",
    "method = (\"IPCC 2013\", \"climate change\", \"GWP 100a\", \"uncertain\")\n",
    "fu_mapped, packages, _ = bd.prepare_lca_inputs(demand=demand, method=method, remapping=False)\n",
    "lca = bc.LCA(demand=fu_mapped, data_objs=packages)\n",
    "lca.lci()\n",
    "lca.lcia()\n",
    "static_score = deepcopy(lca.score)\n",
    "static_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make packages static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all relevant data\n",
    "ei = bd.Database('ecoinvent 3.8 cutoff').datapackage()\n",
    "co = bd.Database('swiss consumption 1.0').datapackage()\n",
    "cf = bd.Method(method).datapackage()\n",
    "\n",
    "# Technosphere\n",
    "tei = ei.filter_by_attribute('matrix', 'technosphere_matrix')\n",
    "tco = co.filter_by_attribute('matrix', 'technosphere_matrix')\n",
    "get_tresource_kind = lambda kind: np.hstack(\n",
    "    [\n",
    "        tei.get_resource(f'ecoinvent_3.8_cutoff_technosphere_matrix.{kind}')[0], \n",
    "        tco.get_resource(f'swiss_consumption_1.0_technosphere_matrix.{kind}')[0]\n",
    "    ]\n",
    ")\n",
    "tindices = get_tresource_kind('indices')\n",
    "tdata = get_tresource_kind('data')\n",
    "tflip = get_tresource_kind('flip')\n",
    "\n",
    "# Biosphere\n",
    "bei = ei.filter_by_attribute('matrix', 'biosphere_matrix')\n",
    "bindices = bei.get_resource('ecoinvent_3.8_cutoff_biosphere_matrix.indices')[0]\n",
    "bdata = bei.get_resource('ecoinvent_3.8_cutoff_biosphere_matrix.data')[0]\n",
    "bdistributions = bei.get_resource('ecoinvent_3.8_cutoff_biosphere_matrix.distributions')[0]\n",
    "\n",
    "# Characterization\n",
    "cindices = cf.get_resource('IPCC_2013_climate_change_GWP_100a_uncertain_matrix_data.indices')[0]\n",
    "cdata = cf.get_resource('IPCC_2013_climate_change_GWP_100a_uncertain_matrix_data.data')[0]\n",
    "cdistributions = cf.get_resource('IPCC_2013_climate_change_GWP_100a_uncertain_matrix_data.distributions')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get technosphere uncertainty boolean array\n",
    "distributions_ei = tei.get_resource('ecoinvent_3.8_cutoff_technosphere_matrix.distributions')[0] \n",
    "has_uncertainty_ei = distributions_ei['uncertainty_type'] >= 2\n",
    "\n",
    "tindices_co = tco.get_resource('swiss_consumption_1.0_technosphere_matrix.indices')[0]\n",
    "has_uncertainty_dict = {}\n",
    "for act in bd.Database('swiss consumption 1.0'):\n",
    "    exchanges = list(act.exchanges())\n",
    "    col = lca.dicts.activity[act.id]\n",
    "    for exc in exchanges:\n",
    "        if exc.get('has_uncertainty', False):\n",
    "            row = lca.dicts.activity[exc.input.id]\n",
    "            has_uncertainty_dict[(exc.input.id, act.id)] = True\n",
    "has_uncertainty_co= np.array([has_uncertainty_dict.get(tuple(ids), False) for ids in tindices_co])\n",
    "\n",
    "has_uncertainty_tech = np.hstack(\n",
    "    [\n",
    "        has_uncertainty_ei,\n",
    "        has_uncertainty_co,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2519098",
   "metadata": {},
   "source": [
    "# Step 1. Remove non influential with contribution analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0040d4b",
   "metadata": {},
   "source": [
    "## Step 1.1 Technosphere & Supply chain traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16abb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fp_sct = write_dir_sct / f\"sct.cutoff_{cutoff:.0e}.maxcalc_{max_calc:.0e}.pickle\"\n",
    "if fp_sct.exists():\n",
    "    tindices_wo_noninf = read_pickle(fp_sct)\n",
    "else:    \n",
    "    tindices_wo_noninf = get_tindices_wo_noninf(lca, cutoff, max_calc)\n",
    "    write_pickle(tindices_wo_noninf, fp_sct)\n",
    "\n",
    "fp_tmask_wo_noninf = write_dir / f\"mask.tech.without_noninf.sct.cutoff_{cutoff:.0e}.maxcalc_{max_calc:.0e}.pickle\"\n",
    "if fp_tmask_wo_noninf.exists():\n",
    "    tmask_wo_noninf = read_pickle(fp_tmask_wo_noninf)\n",
    "else:\n",
    "    tmask_wo_noninf = get_mask(tindices, tindices_wo_noninf)\n",
    "    write_pickle(tmask_wo_noninf, fp_tmask_wo_noninf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34b8bf",
   "metadata": {},
   "source": [
    "## Step 1.2 Biosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03016fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bindices_wo_noninf = get_bindices_wo_noninf(lca)\n",
    "fp_bmask_wo_noninf = write_dir / \"mask.bio.without_noninf.pickle\"\n",
    "if fp_bmask_wo_noninf.exists():\n",
    "    bmask_wo_noninf = read_pickle(fp_bmask_wo_noninf)\n",
    "else:\n",
    "    bmask_wo_noninf = get_mask(bindices, bindices_wo_noninf)\n",
    "    write_pickle(bmask_wo_noninf, fp_bmask_wo_noninf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf2041",
   "metadata": {},
   "source": [
    "## Step 1.3 Characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cindices_wo_noninf = get_cindices_wo_noninf(lca)\n",
    "fp_cmask_wo_noninf = write_dir / \"mask.cf.without_noninf.pickle\"\n",
    "if fp_cmask_wo_noninf.exists():\n",
    "    cmask_wo_noninf = read_pickle(fp_cmask_wo_noninf)\n",
    "else:\n",
    "    cmask_wo_noninf = get_mask(cindices, cindices_wo_noninf)\n",
    "    write_pickle(cmask_wo_noninf, fp_cmask_wo_noninf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6186f",
   "metadata": {},
   "source": [
    "# Step 2. Run local SA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bab574",
   "metadata": {},
   "source": [
    "## 2.1 Technosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_local_sa_tech(\n",
    "    matrix_type,\n",
    "    fu_mapped,\n",
    "    packages,\n",
    "    tindices,\n",
    "    tdata,\n",
    "    has_uncertainty_tech,\n",
    "    mask_tech_without_noninf,\n",
    "    flip_tech,\n",
    "    factors,\n",
    "    write_dir,\n",
    "):\n",
    "    for i, factor in enumerate(factors):\n",
    "        fp_factor = write_dir / f\"local_sa.tech.factor_{factor:.0e}.cutoff_{cutoff:.0e}.maxcalc_{max_calc:.0e}.pickle\"\n",
    "        if fp_factor.exists():\n",
    "            local_sa_current = read_pickle(fp_factor)\n",
    "        else:\n",
    "            local_sa_current = run_local_sa(\n",
    "                matrix_type,\n",
    "                fu_mapped,\n",
    "                packages,\n",
    "                indices_tech,\n",
    "                data_tech,\n",
    "                has_uncertainty_tech,\n",
    "                mask_tech_without_noninf,\n",
    "                flip_tech,\n",
    "                factor,\n",
    "            )\n",
    "            write_pickle(local_sa_current, fp_factor)\n",
    "        if i == 0:\n",
    "            local_sa = deepcopy(local_sa_current)\n",
    "        else:\n",
    "            local_sa = {k: np.hstack([local_sa[k], local_sa_current[k]]) for k in local_sa.keys()}\n",
    "    return local_sa\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fp_local_sa_tech = write_dir / f\"local_sa.tech.cutoff_{cutoff:.0e}.maxcalc_{max_calc:.0e}.pickle\"\n",
    "if fp_local_sa_tech.exists():\n",
    "    local_sa_tech = read_pickle(fp_local_sa_tech)\n",
    "else:\n",
    "    local_sa_tech = run_local_sa_tech(\n",
    "        \"technosphere\",\n",
    "        fu_mapped,\n",
    "        packages,\n",
    "        indices_tech,\n",
    "        data_tech,\n",
    "        has_uncertainty_tech,\n",
    "        mask_tech_without_noninf,\n",
    "        flip_tech,\n",
    "        [1/const_factor, const_factor],\n",
    "        write_dir\n",
    "    )\n",
    "    write_pickle(local_sa_tech, fp_local_sa_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad418613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if fp_mask_tech_without_lowinf.exists():\n",
    "#     mask_tech_without_lowinf = read_pickle(fp_mask_tech_without_lowinf)\n",
    "# else:\n",
    "#     mask_tech_without_lowinf = get_mask(indices_tech, use_indices_tech_without_lowinf)\n",
    "#     write_pickle(mask_tech_without_lowinf, fp_mask_tech_without_lowinf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46a6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO cutoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4cda2",
   "metadata": {},
   "source": [
    "## 2.2 Biosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038225d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fp_local_sa_bio = write_dir / f\"local_sa.bio.pickle\"\n",
    "if fp_local_sa_bio.exists():\n",
    "    local_sa_bio = read_pickle(fp_local_sa_bio)\n",
    "else:\n",
    "    local_sa_bio = run_local_sa(\n",
    "        \"biosphere\",\n",
    "        fu_mapped,\n",
    "        packages,\n",
    "        indices_bio,\n",
    "        data_bio,\n",
    "        distributions_bio,\n",
    "        mask_bio_without_noninf,\n",
    "        None,\n",
    "        const_factor,\n",
    "    )\n",
    "    write_pickle(local_sa_bio, fp_local_sa_bio)\n",
    "    \n",
    "#     mask_bio_without_lowinf = get_mask(indices_bio, use_indices_bio_without_lowinf)\n",
    "#     assert sum(mask_bio_without_lowinf) == len(use_indices_bio_without_lowinf)\n",
    "#     mask_bio_without_lowinf = get_mask(indices_bio, use_indices_bio_without_lowinf)\n",
    "#     write_pickle(mask_bio_without_lowinf, fp_mask_bio_without_lowinf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f627a",
   "metadata": {},
   "source": [
    "## 2.3 Characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fp_local_sa_cf = write_dir / f\"local_sa.cf.pickle\"\n",
    "if fp_local_sa_cf.exists():\n",
    "    local_sa_cf = read_pickle(fp_local_sa_cf)\n",
    "else:\n",
    "    local_sa_cf = run_local_sa(\n",
    "        \"characterization\",\n",
    "        fu_mapped,\n",
    "        packages,\n",
    "        indices_cf,\n",
    "        data_cf,\n",
    "        distributions_cf,\n",
    "        mask_cf_without_noninf,\n",
    "        None,\n",
    "        const_factor,\n",
    "    )\n",
    "    write_pickle(local_sa_cf, fp_local_sa_cf)\n",
    "#     mask_cf_without_lowinf = get_mask(indices_cf, use_indices_cf_without_lowinf)\n",
    "#     assert sum(mask_cf_without_lowinf) == len(use_indices_cf_without_lowinf)\n",
    "#     mask_cf_without_lowinf = get_mask(indices_cf, use_indices_cf_without_lowinf)\n",
    "#     write_pickle(mask_cf_without_lowinf, fp_mask_cf_without_lowinf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab724ee",
   "metadata": {},
   "source": [
    "## 2.4 Virtual markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca8753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from akula.virtual_markets import DATA_DIR\n",
    "fp_virtual_markets = DATA_DIR / \"virtual-markets.zip\"\n",
    "dp = bwp.load_datapackage(ZipFS(fp_virtual_markets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_vm_unordered = dp.get_resource('virtual markets.indices')[0]\n",
    "mask_vm_tech = get_mask(indices_tech, indices_vm_unordered)\n",
    "# flip_vm = dp.get_resource('virtual markets.flip')[0]\n",
    "indices_vm = indices_tech[mask_vm_tech]\n",
    "data_vm = data_tech[mask_vm_tech]\n",
    "flip_vm = flip_tech[mask_vm_tech]\n",
    "distributions_vm = np.ones(len(indices_vm), dtype=bool)\n",
    "mask_vm = distributions_vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023334a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fp_local_sa_vm = write_dir / f\"local_sa.virtual_markets.pickle\"\n",
    "if fp_local_sa_cf.exists():\n",
    "    local_sa_vm = run_local_sa(\n",
    "        \"technosphere\",\n",
    "        fu_mapped,\n",
    "        packages,\n",
    "        indices_vm,\n",
    "        data_vm,\n",
    "        distributions_vm,\n",
    "        mask_vm,\n",
    "        flip_vm,\n",
    "        const_factor,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186bb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0178854a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb64d550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d0ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ee83e96",
   "metadata": {},
   "source": [
    "# 2.4 Remove lowly influential based on variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add static score\n",
    "local_sa_list = [local_sa_tech, local_sa_bio, local_sa_cf]\n",
    "for dict_ in local_sa_list:\n",
    "    values = np.vstack(list(dict_.values()))\n",
    "    values = np.hstack([values, np.ones((len(values), 1))*static_score])\n",
    "    variances = np.var(values, axis=1)\n",
    "    for i,k in enumerate(dict_.keys()):\n",
    "#         dict_.update({k: values[i,:]})\n",
    "        dict_[k] = {\n",
    "            \"arr\": values[i,:],\n",
    "            \"var\": variances[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97155e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find threshold for variance\n",
    "num_parameters_step2 = 100\n",
    "# Collect all variances\n",
    "variances = np.array([v['var'] for dict_ in local_sa_list for k,v in dict_.items() ])\n",
    "variances = np.sort(variances)[-1::-1]\n",
    "variances_threshold = variances[:num_parameters_step2][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lowly influential\n",
    "get_indices_high_variance = lambda dict_: \\\n",
    "    [k for k in dict_ if dict_[k]['var'] >= variances_threshold]\n",
    "\n",
    "use_indices_tech_without_lowinf = get_indices_high_variance(local_sa_tech)\n",
    "mask_tech_without_lowinf = get_mask(indices_tech, use_indices_tech_without_lowinf)\n",
    "\n",
    "use_indices_bio_without_lowinf = get_indices_high_variance(local_sa_bio)\n",
    "mask_bio_without_lowinf = get_mask(indices_bio, use_indices_bio_without_lowinf)\n",
    "\n",
    "use_indices_cf_without_lowinf = get_indices_high_variance(local_sa_cf)\n",
    "mask_cf_without_lowinf = get_mask(indices_cf, use_indices_cf_without_lowinf)\n",
    "\n",
    "assert sum(mask_tech_without_lowinf) + sum(mask_bio_without_lowinf) + sum(mask_cf_without_lowinf) == num_parameters_step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c7eed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79fb7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a4587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
