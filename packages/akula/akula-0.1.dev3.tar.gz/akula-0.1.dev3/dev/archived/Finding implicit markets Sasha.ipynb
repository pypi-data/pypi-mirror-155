{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79eb6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from thefuzz import fuzz\n",
    "from gsa_framework.utils import write_pickle, read_pickle\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import lognorm\n",
    "import copy\n",
    "from scipy.stats import dirichlet\n",
    "import numpy as np\n",
    "import matplotlib.backends.backend_pdf\n",
    "from pathlib import Path\n",
    "import bw_processing as bwp\n",
    "from fs.zipfs import ZipFS\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/akim/PycharmProjects/akula\")\n",
    "\n",
    "from akula.markets import get_dirichlet_scales, DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d7a124-8aa8-49d9-a3fb-a309a3d7aecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 3 object(s):\n",
       "\tbiosphere3\n",
       "\tecoinvent 3.8 cutoff\n",
       "\tswiss consumption 1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.projects.set_current('GSA for archetypes')\n",
    "bd.databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4385f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"/Users/akim/PycharmProjects/akula/dev/write_files/gsa_for_archetypes/monte_carlo/generic-markets.500.11111000.pickle\"\n",
    "mc_data_gms = read_pickle(fp)\n",
    "fp_option = DATA_DIR / \"generic-markets.zip\"\n",
    "dp_option = bwp.load_datapackage(ZipFS(fp_option))\n",
    "\n",
    "indices = dp_option.get_resource('generic markets.indices')[0]\n",
    "data = dp_option.get_resource('generic markets.data')[0]\n",
    "flip = dp_option.get_resource('generic markets.flip')[0]\n",
    "\n",
    "co = bd.Database('swiss consumption 1.0')\n",
    "hh_average = [act for act in co if \"ch hh average consumption aggregated, years 151617\" == act['name']][0]\n",
    "method = (\"IPCC 2013\", \"climate change\", \"GWP 100a\", \"uncertain\")\n",
    "seed = 11111000\n",
    "\n",
    "me = bd.Method(method)\n",
    "bs = bd.Database(\"biosphere3\")\n",
    "ei = bd.Database(\"ecoinvent 3.8 cutoff\")\n",
    "co_name = \"swiss consumption 1.0\"\n",
    "co = bd.Database(co_name)\n",
    "list_ = [me, bs, ei, co]\n",
    "dps = [\n",
    "    bwp.load_datapackage(ZipFS(db.filepath_processed()))\n",
    "    for db in list_\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab50cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_data_gms[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e150d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_gms = bwp.create_datapackage()\n",
    "dp_gms.add_persistent_array(\n",
    "    matrix = 'technosphere_matrix',\n",
    "    data_array = data,\n",
    "    indices_array = indices,\n",
    "    flip_array = flip,\n",
    "    name='one value',\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2calc as bc\n",
    "lca = bc.LCA({hh_average.id: 1}, data_objs=dps+[dp_check], use_distributions=True, use_arrays=True, seed_override=seed,)\n",
    "lca.lci()\n",
    "lca.lcia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0de524",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [lca.score for _, _ in zip(lca, range(5))]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954df688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e1ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457583f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945a8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b518972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b35a4b54-4e97-4121-b01a-422358dcec7c",
   "metadata": {},
   "source": [
    "The inspiration for these virtual markets was the input of 'soybean' to 'market for soybean, feed' which has a reference product 'soybean, feed'. We can't just test exact matching, need to be a bit [more flexible](https://github.com/seatgeek/thefuzz) on these virtual markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9c617-b815-4f3e-94b3-53635e1a6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    return fuzz.partial_ratio(a, b) > 90 or fuzz.ratio(a, b) > 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c989ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_uncertain_implicit_markets(database):\n",
    "    db = bd.Database(database)\n",
    "\n",
    "    found = {}\n",
    "    \n",
    "    for act in tqdm(db):\n",
    "        rp = act.get(\"reference product\")\n",
    "        if not rp:\n",
    "            continue\n",
    "            \n",
    "        inpts = defaultdict(list)\n",
    "        for exc in act.technosphere():\n",
    "            if exc.input == exc.output:\n",
    "                continue\n",
    "            elif exc['uncertainty type'] < 2:\n",
    "                continue\n",
    "            inpts[exc.input['reference product']].append(exc)\n",
    "            \n",
    "        for key, lst in inpts.items():\n",
    "            if len(lst) > 1 and similar(rp, key) and 0.98 <= sum([exc['amount'] for exc in lst]) <= 1.02:\n",
    "                found[act] = lst\n",
    "            \n",
    "    return found\n",
    "\n",
    "def find_markets(database):\n",
    "    db = bd.Database(database)\n",
    "\n",
    "    found = {}\n",
    "    \n",
    "    for act in tqdm(db):\n",
    "        if 'market group' in act['name']:\n",
    "            continue\n",
    "        if 'market' in act['name']:\n",
    "            rp = act.get(\"reference product\")\n",
    "            if not rp:\n",
    "                continue\n",
    "\n",
    "            inpts = defaultdict(list)\n",
    "            for exc in act.technosphere():\n",
    "                if exc.input == exc.output:\n",
    "                    continue\n",
    "                inpts[exc.input['reference product']].append(exc)\n",
    "\n",
    "            for key, lst in inpts.items():\n",
    "                if len(lst) > 1 and rp==key and 0.98 <= sum([exc['amount'] for exc in lst]) <= 1.02:\n",
    "                    found[act] = lst\n",
    "            \n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d512b87-e499-44c3-aa00-b517bdac2abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ei_name = \"ecoinvent 3.8 cutoff\"\n",
    "# found = find_uncertain_implicit_markets(ei_name)\n",
    "# markets = find_markets(ei_name)\n",
    "# write_pickle(found, \"implicit_markets.pickle\")\n",
    "# write_pickle(markets, \"normal_markets.pickle\")\n",
    "found = read_pickle(\"implicit_markets.pickle\")\n",
    "markets = read_pickle(\"normal_markets.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4e0c4-88e1-4807-8546-0f265ecbbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = list(found)[32]\n",
    "# ng, found[ng]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6832e88b-06ba-4513-b7ff-d718756de44a",
   "metadata": {},
   "source": [
    "We can use the [dirichlet](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.dirichlet.html) to model parameters with a fixed sum, but this distribution is sensitive to the concentration values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63660226",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_beta_variance = lambda a,b: a*b/(a+b)**2/(a+b+1)\n",
    "get_beta_skewness = lambda a,b: 2*(b-a)*((a+b+1)**0.5) / (a+b+2) / (a*b)**0.5\n",
    "\n",
    "get_lognormal_variance = lambda loc, scale: (np.exp(scale**2)-1) * np.exp(2*loc+scale**2)\n",
    "get_lognormal_skewness = lambda loc, scale: (np.exp(scale**2)+2) * ((np.exp(scale**2)-1)**0.5)\n",
    "\n",
    "def get_dirichlet_scaling_factor(alpha_exc_dict):\n",
    "    alphas = list(alpha_exc_dict.keys())\n",
    "    beta = sum(alphas)\n",
    "    alpha_threshold = np.mean(alphas)\n",
    "    scaling_factors, scaling_factors_skewness = [], []\n",
    "    for ialpha, iexc in alpha_exc_dict.items():\n",
    "        if ialpha >= alpha_threshold:\n",
    "            assert iexc['uncertainty type'] == 2\n",
    "            loc = iexc['loc']\n",
    "            scale = iexc['scale']\n",
    "            beta_variance = get_beta_variance(ialpha, beta)\n",
    "            lognormal_variance = get_lognormal_variance(loc, scale)\n",
    "            beta_skewness = get_beta_skewness(ialpha, beta)\n",
    "            lognormal_skewness = get_lognormal_skewness(loc, scale)\n",
    "            scaling_factors.append(beta_variance / lognormal_variance * 2)\n",
    "            scaling_factors_skewness.append(beta_skewness / lognormal_skewness)\n",
    "    scaling_factor = np.mean(scaling_factors)\n",
    "    scaling_factor_skewness = np.mean(scaling_factors_skewness)\n",
    "#     print(scaling_factors, scaling_factor)\n",
    "#     print(scaling_factors_skewness, scaling_factor_skewness)\n",
    "    return max(scaling_factor, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ae6e9c-b2d2-40b6-b695-b16b8ae29f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = matplotlib.backends.backend_pdf.PdfPages(\"implicit_market_figures.pdf\")\n",
    "write_figs = Path(\"implicit_markets\")\n",
    "write_figs.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "dist_ = {}\n",
    "num_bins = 100\n",
    "count=0\n",
    "\n",
    "for ng, current in found.items():\n",
    "\n",
    "    rows=len(current)\n",
    "\n",
    "    showlegend = True\n",
    "    x = np.array([exc['amount'] for exc in current])\n",
    "    alpha = x.copy()\n",
    "    alpha_exc_dict = {alpha[i]: current[i] for i in range(len(alpha))}\n",
    "    scaling_factors = [get_dirichlet_scaling_factor(alpha_exc_dict), 250, 500]\n",
    "\n",
    "    scaling_factors_str = [f\"SF={sf:5.3f}\" for sf in scaling_factors]\n",
    "    fig = make_subplots(\n",
    "        rows=rows, \n",
    "        cols=3,\n",
    "        horizontal_spacing=0.2,\n",
    "        subplot_titles=scaling_factors_str\n",
    "    )\n",
    "\n",
    "    for j,scaling_factor in enumerate(scaling_factors):\n",
    "        rvs = dirichlet.rvs(alpha*scaling_factor, size=1000)\n",
    "        for i,exc in enumerate(current):\n",
    "            Y = rvs[:,i]\n",
    "            bins_ = np.linspace(min(Y), max(Y), num_bins+1, endpoint=True)\n",
    "            Y_samples, _ = np.histogram(Y, bins=bins_, density=True)\n",
    "            # Given distribution\n",
    "            assert exc['uncertainty type']==2\n",
    "            loc = exc['loc']\n",
    "            scale = exc['scale']  \n",
    "            midbins = (bins_[1:]+bins_[:-1])/2\n",
    "            Y_distr = lognorm.pdf(midbins, s=scale, scale=np.exp(loc))\n",
    "            distance = np.sqrt(sum(Y_distr-Y_samples)**2)/max(Y_distr)\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x = midbins,\n",
    "                    y = Y_samples,\n",
    "                    line_color = 'blue',\n",
    "                    name='Dirichlet samples',\n",
    "                    showlegend=showlegend,\n",
    "                ),\n",
    "                row=i+1,\n",
    "                col=j+1,\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x = midbins,\n",
    "                    y = Y_distr,\n",
    "                    line_color = 'red',\n",
    "                    name='Defined distribution',\n",
    "                    showlegend=showlegend,\n",
    "                ),\n",
    "                row=i+1,\n",
    "                col=j+1,\n",
    "            )\n",
    "            showlegend=False\n",
    "            fig.update_yaxes(\n",
    "                title_text=f\"ED={distance:5.3f}\",\n",
    "                row=i+1,\n",
    "                col=j+1,\n",
    "            )\n",
    "    fig.update_layout(\n",
    "        width=700,\n",
    "        height=250*rows,\n",
    "        legend=dict(\n",
    "            yanchor=\"top\",\n",
    "            y=-0.2,\n",
    "            xanchor=\"left\",\n",
    "            x=0.01,\n",
    "            orientation='h',\n",
    "        )\n",
    "    )\n",
    "    fig.write_html(write_figs / \"{}_{}_{}.html\".format(count, ng['name'][:20], ng['location'][:3]))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6dc8de-fc80-4945-8af8-5bc357b52b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.displot(rvs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95241375-bbb2-474b-8b31-2da49e959832",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs = dirichlet.rvs(alpha * 500, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe26988-4ba6-4b82-ac11-565885f13c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.displot(rvs[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10188a32-ece2-420a-bf8b-ecd21a53f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.displot(rvs[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475df03b-0847-442d-8f01-a8cc14d55eaf",
   "metadata": {},
   "source": [
    "We can use these new values in Monte Carlo assessment (in place of the independent sampling which results in broken mass balances). The exact approach here will probably be different; for example, one could use trade statistics to create regional markets with much higher precision.\n",
    "\n",
    "The underlying concepts in the following are documented in [bw_processing](https://github.com/brightway-lca/bw_processing) and [matrix_utils](https://github.com/brightway-lca/matrix_utils). In this notebook we will use in-memory datapackages for our fixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410ddb7-b372-4236-a530-efb3bace4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw_processing as bwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71442143-aa41-4d12-b286-5933c8a34fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_array = np.array([(exc.input.id, exc.output.id) for exc in found[ng]], dtype=bwp.INDICES_DTYPE)\n",
    "\n",
    "# Redefine alpha to make sure order is consistent\n",
    "# Transpose to get rows or exchange indices, columns of possible values\n",
    "data_array = dirichlet.rvs(np.array([exc['amount'] for exc in found[ng]]) * 500, size=1000).T\n",
    "\n",
    "# technosphere inputs must be flipped\n",
    "flip_array = np.ones(len(found[ng]), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb09c7-d077-4635-ba42-048a86a97247",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = bwp.create_datapackage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a3e862-f097-44db-8870-632635e7e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.add_persistent_array(\n",
    "    matrix=\"technosphere_matrix\",\n",
    "    data_array=data_array,\n",
    "    name=\"ng-fix-dz-es\",\n",
    "    indices_array=indices_array,\n",
    "    flip_array=flip_array,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d254d-cb37-42a3-b231-2c2bab4f64fc",
   "metadata": {},
   "source": [
    "Compare Monte Carlo results with and without the fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7149a0d-40c5-47ac-b05f-11e4e05ec745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipcc = ('IPCC 2013', 'climate change', 'GWP 100a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0d572-217a-4fe5-a427-a505fb62e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, data_objs, _ = bd.prepare_lca_inputs({ng: 1}, method=ipcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde83f2d-847f-480e-8386-cd4a94c19acd",
   "metadata": {},
   "source": [
    "Default is to use three datapackages: biosphere database, ecoinvent database, and LCIA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf7938-8f73-41db-841e-184b0976b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3901b-7445-4fbe-b566-2c891c8a1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2calc as bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0b657-6120-4926-8263-566c9f46b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "lca = bc.LCA({ng.id: 1}, data_objs=data_objs, use_distributions=True)\n",
    "lca.lci()\n",
    "lca.lcia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa17120-d9af-4eb4-8e18-990086015888",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmodified = np.array([lca.score for _ in zip(lca, range(250))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb2fd1-0172-40d9-bb64-0cb8a28bd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = bc.LCA({ng.id: 1}, data_objs=data_objs + [dp], use_arrays=True, use_distributions=True)\n",
    "fixed.lci()\n",
    "fixed.lcia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b422e3e-2722-461b-a6e6-b1961cb960cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified = np.array([fixed.score for _ in zip(fixed, range(250))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2c1751-0dee-4035-94e4-2d156634ee8c",
   "metadata": {},
   "source": [
    "Uncertainty for this example is not huge, so difference is not obvious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a5ec5-67dc-4b55-9e6d-f94cd9af766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(modified), np.std(modified), np.mean(unmodified), np.std(modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc0cf9-2210-483c-b055-0c17f11518d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exc in found[ng]:\n",
    "    lca.redo_lcia({exc.input.id: 1})\n",
    "    print(lca.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83f6a0-1cff-41d9-8f7b-b53820b1976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exc in found[ng]:\n",
    "    print(exc['scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f60fc1-9cf2-4aca-8721-14fa3ca00f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([\n",
    "    lca.technosphere_matrix[lca.dicts.product[row], lca.dicts.activity[col]]\n",
    "    for row, col in indices_array\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d2ec3-8040-43a0-ab37-a1f0a030219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([\n",
    "    fixed.technosphere_matrix[fixed.dicts.product[row], fixed.dicts.activity[col]]\n",
    "    for row, col in indices_array\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd322599-70f1-487f-9348-35a0f6794819",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.displot(unmodified, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1237b0-7aa6-46a9-9c36-fc8b5651f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.displot(modified, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e7c9e",
   "metadata": {},
   "source": [
    "# [didn't work] Sampling with presamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2644fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ei_name = \"ecoinvent 3.8 cutoff\"\n",
    "\n",
    "in_total = sum([exc['amount'] for exc in found[ng]])\n",
    "out_total = 1\n",
    "static_ratio = in_total / out_total if out_total != 0 else inf\n",
    "static_balance = in_total - out_total\n",
    "\n",
    "activity_params = []\n",
    "for i,exc in enumerate(found[ng]):\n",
    "#     if 'formula' in exc:\n",
    "#         print(i)\n",
    "#         break\n",
    "    param_name = f\"market_param_{i}\"\n",
    "    activity_params.append(\n",
    "        {\n",
    "            'name': param_name,\n",
    "            'amount': exc.get('amount', 0),\n",
    "            'uncertainty type': exc.get('uncertainty type', 0),\n",
    "            'loc': exc.get('loc', exc.get('amount', 0)),\n",
    "            'scale': exc.get('scale'),\n",
    "            'negative': exc.get('negative', False),\n",
    "            'database': ei_name,\n",
    "            'code': ng.get('code'),\n",
    "        }\n",
    "    )\n",
    "    if exc.get('uncertainty type', 0) > 1:\n",
    "        exc['formula'] = \"{} * scaling\".format(param_name)\n",
    "    else:\n",
    "        exc['formula'] = param_name\n",
    "    exc.save()\n",
    "    if exc.get('variable name', False):\n",
    "        exc['variable name temp'] = exc['variable name']\n",
    "        exc['variable name'] = []\n",
    "        exc.save()\n",
    "    \n",
    "activity_params.append(\n",
    "    {\n",
    "        'name': 'static_ratio',\n",
    "        'database': ei_name,\n",
    "        'code': ng['code'],\n",
    "        'amount': static_ratio,\n",
    "        'uncertainty type': 0,\n",
    "        'loc': static_ratio,\n",
    "    }\n",
    ")\n",
    "out_term = \"1\"\n",
    "const_in_term = \"0\"\n",
    "var_in_term = \"(market_param_0 + market_param_1)\"\n",
    "activity_params.append(\n",
    "    {\n",
    "        'name': 'scaling',\n",
    "        'formula': \"({}*{}-{})/({})\".format(static_ratio, out_term, const_in_term, var_in_term),\n",
    "        'database': ei_name,\n",
    "        'code': ng['code'],\n",
    "    },\n",
    ")\n",
    "activity_params.append(\n",
    "    {\n",
    "        'name': 'ratio',\n",
    "        'formula': \"(scaling * {} + {})/{}\".format(var_in_term, const_in_term, out_term),\n",
    "        'database': ei_name,\n",
    "        'code': ng['code'],\n",
    "    },\n",
    ")\n",
    "\n",
    "group = 'my_market_2022_04'\n",
    "iterations = 10\n",
    "bd.parameters.new_activity_parameters(activity_params, group, True)\n",
    "# bd.parameters.add_exchanges_to_group(group, ng)\n",
    "bd.parameters.recalculate()\n",
    "# pbm = PBM(group)\n",
    "# pbm.load_parameter_data()\n",
    "# pbm.calculate_stochastic(iterations, update_amounts=True)\n",
    "# pbm.calculate_matrix_presamples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale lognormal distributions\n",
    "iterations = 1000\n",
    "Y_samples = np.zeros((0,iterations))\n",
    "for i,exc in enumerate(found[ng]):\n",
    "    # Given distribution\n",
    "    if exc['uncertainty type']==2:\n",
    "        loc = exc['loc']\n",
    "        scale = exc['scale']  \n",
    "#         x = np.linspace(\n",
    "#             lognorm.ppf(0.01, s=scale, scale=np.exp(loc)), \n",
    "#             lognorm.ppf(0.99, s=scale, scale=np.exp(loc)), \n",
    "#             num_bins,\n",
    "#         )\n",
    "        x = np.linspace(0,1,iterations+1)\n",
    "        Y_samples = np.vstack([Y_samples, lognorm.pdf(x[1:], s=scale, scale=np.exp(loc))])\n",
    "Y_scaled = Y_samples / Y_samples.sum(axis=0)\n",
    "Y_scaled = Y_scaled.T\n",
    "Y_scaled.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
