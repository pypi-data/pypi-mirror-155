
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sysidentpy.narmax_base &#8212; NARMAX models</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=84ace793992934648b4de8eed757e5a2" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.9d8b4a8b9bb19db25eeaddc40d639ba2.js"></script>
    <link rel="canonical" href="http://sysidentpy.org/_modules/sysidentpy/narmax_base.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<div class="col-12 col-md-3 bd-sidebar site-navigation " id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/sysidentpy-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NARMAX models</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../installation.html">
   Install Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction_to_narmax.html">
   A brief introduction to NARMAX models.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../user_guide.html">
   User Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dev_guide.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../notebooks.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/basic_steps.html">
     Presenting main functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/air_passenger_benchmark.html">
     Air Passenger benchmark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/load_forecasting_benchmark.html">
     Load forecasting benchmark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/PV_forecasting_benchmark.html">
     PV forecasting benchmark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/multiple_inputs_example.html">
     Multiple Inputs usage
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/fourier_basis_function.html">
     Fourier Basis Function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/information_criteria_examples.html">
     Information Criteria - Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/extended_least_squares.html">
     Extended Least Squares
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/defining_lags.html">
     Setting specific lags
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/parameter_estimation.html">
     Parameter Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/metamss.html">
     Meta-Model Structure Selection (MetaMSS) algorithm for building Polynomial NARX models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/aols.html">
     Using the Accelerated Orthogonal Least-Squares algorithm for building Polynomial NARX models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/entropic_regression.html">
     Identification of an electromechanical system using Entropic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/f_16_benchmark.html">
     Example: F-16 Ground Vibration Test benchmark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/narx_neural_network.html">
     Building NARX Neural Network using Sysidentpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/general_estimators.html">
     Building NARX models using general estimators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/simulating_a_predefined_model.html">
     Simulate a Predefined Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/identification_of_an_electromechanical_system.html">
     Identification of an electromechanical system
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../examples/n_steps_ahead_prediction.html">
     Example: N-steps-ahead prediction - F-16 Ground Vibration Test benchmark
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../changelog/v0.2.0.html">
   Changes in SysIdentPy
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../code.html">
   Code
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<!-- This is an invisible pixel that we watch to see if we've scrolled. -->
<div class="sbt-scroll-pixel-helper"></div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            <div class="topbar-left">
                
                <label class="nav-toggle-button" for="__navigation">
                    <div class="visually-hidden">Toggle navigation</div>
                    <i class="fas fa-bars"></i>
                </label>
                
            </div>
            
            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/wilsonrljr/sysidentpy/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/wilsonrljr/sysidentpy//issues/new?title=Issue%20on%20page%20%2F_modules/sysidentpy/narmax_base.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            
              <div>
                
  <h1>Source code for sysidentpy.narmax_base</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Base classes for NARMAX estimator.&quot;&quot;&quot;</span>

<span class="c1"># Authors:</span>
<span class="c1">#           Wilson Rocha Lacerda Junior &lt;wilsonrljr@outlook.com&gt;</span>
<span class="c1"># License: BSD 3 clause</span>


<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span><span class="p">,</span> <span class="n">combinations_with_replacement</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">.utils._check_arrays</span> <span class="kn">import</span> <span class="n">_check_positive_int</span><span class="p">,</span> <span class="n">_num_features</span><span class="p">,</span> <span class="n">check_X_y</span>


<div class="viewcode-block" id="GenerateRegressors"><a class="viewcode-back" href="../../code.html#sysidentpy.narmax_base.GenerateRegressors">[docs]</a><span class="k">class</span> <span class="nc">GenerateRegressors</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Polynomial NARMAX model</span>

<span class="sd">    Provides the main functions to generate the regressor dictionary</span>
<span class="sd">    and regressor codes for polynomial basis.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="GenerateRegressors.create_narmax_code"><a class="viewcode-back" href="../../code.html#sysidentpy.narmax_base.GenerateRegressors.create_narmax_code">[docs]</a>    <span class="k">def</span> <span class="nf">create_narmax_code</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">non_degree</span><span class="p">,</span> <span class="n">xlag</span><span class="p">,</span> <span class="n">ylag</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create the code representation of the regressors.</span>

<span class="sd">        This function generates a codification from all possibles</span>
<span class="sd">        regressors given the maximum lag of the input and output.</span>
<span class="sd">        This is used to write the final terms of the model in a</span>
<span class="sd">        readable form. [1001] -&gt; y(k-1).</span>
<span class="sd">        This code format was based on a dissertation from UFMG. See</span>
<span class="sd">        reference below.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        non_degree : int</span>
<span class="sd">            The desired maximum nonlinearity degree.</span>
<span class="sd">        ylag : int</span>
<span class="sd">            The maximum lag of output regressors.</span>
<span class="sd">        xlag : int</span>
<span class="sd">            The maximum lag of input regressors.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        max_lag : int</span>
<span class="sd">            This value can be used by another functions.</span>
<span class="sd">        regressor_code : ndarray of int</span>
<span class="sd">            Matrix codification of all possible regressors.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        The codification is defined as:</span>

<span class="sd">        &gt;&gt;&gt; 100n = y(k-n)</span>
<span class="sd">        &gt;&gt;&gt; 200n = u(k-n)</span>
<span class="sd">        &gt;&gt;&gt; [100n 100n] = y(k-n)y(k-n)</span>
<span class="sd">        &gt;&gt;&gt; [200n 200n] = u(k-n)u(k-n)</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Master Thesis: Barbosa, Alípio Monteiro.</span>
<span class="sd">            Técnicas de otimização bi-objetivo para a determinação</span>
<span class="sd">            da estrutura de modelos NARX (2010).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">non_degree</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">non_degree</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;non_degree must be integer and &gt; zero. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">non_degree</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ylag</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">ylag</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;ylag must be integer or list and &gt; zero. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">ylag</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xlag</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span>
            <span class="c1"># or np.min(np.minimum(xlag, 1)) &lt; 1):</span>
            <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">([[</span><span class="n">xlag</span><span class="p">]]))))</span> <span class="o">&lt;</span> <span class="mi">1</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;xlag must be integer or list and &gt; zero. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">xlag</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">n_inputs</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;n_inputs must be integer and &gt; zero. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">n_inputs</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ylag</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="c1"># create only the lags passed from list</span>
            <span class="n">y_vec</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">y_vec</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">lag</span> <span class="o">+</span> <span class="mi">1000</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="n">ylag</span><span class="p">])</span>
            <span class="n">y_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_vec</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># create a range of lags if passed a int value</span>
            <span class="n">y_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1001</span><span class="p">,</span> <span class="mi">1001</span> <span class="o">+</span> <span class="n">ylag</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xlag</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n_inputs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># create only the lags passed from list</span>
            <span class="n">x_vec_tmp</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">x_vec_tmp</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">lag</span> <span class="o">+</span> <span class="mi">2000</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="n">xlag</span><span class="p">])</span>
            <span class="n">x_vec_tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_vec_tmp</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xlag</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n_inputs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># create a range of lags if passed a int value</span>
            <span class="n">x_vec_tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2001</span><span class="p">,</span> <span class="mi">2001</span> <span class="o">+</span> <span class="n">xlag</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">n_inputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># only list are allowed if n_inputs &gt; 1</span>
            <span class="c1"># the user must entered list of the desired lags explicitly</span>
            <span class="n">x_vec_tmp</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xlag</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n_inputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># create 200n, 300n,..., 400n to describe each input</span>
                    <span class="n">x_vec_tmp</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">lag</span> <span class="o">+</span> <span class="mi">2000</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">1000</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="n">xlag</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xlag</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n_inputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">x_vec_tmp</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2001</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">2001</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">1000</span> <span class="o">+</span> <span class="n">xlag</span><span class="p">[</span><span class="n">i</span><span class="p">])]</span>
                    <span class="p">)</span>

        <span class="k">if</span> <span class="n">n_inputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># if x_vec is a nested list, ensure all elements are arrays</span>
            <span class="n">all_arrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x_vec_tmp</span><span class="p">]</span>
            <span class="n">x_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">all_arrays</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_vec</span> <span class="o">=</span> <span class="n">x_vec_tmp</span>

        <span class="k">return</span> <span class="n">x_vec</span><span class="p">,</span> <span class="n">y_vec</span></div>

    <span class="k">def</span> <span class="nf">regressor_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">non_degree</span><span class="p">,</span> <span class="n">xlag</span><span class="p">,</span> <span class="n">ylag</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;NARMAX&quot;</span><span class="p">):</span>
        <span class="n">x_vec</span><span class="p">,</span> <span class="n">y_vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_narmax_code</span><span class="p">(</span><span class="n">non_degree</span><span class="p">,</span> <span class="n">xlag</span><span class="p">,</span> <span class="n">ylag</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">)</span>
        <span class="n">reg_aux</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NARMAX&quot;</span><span class="p">:</span>
            <span class="n">reg_aux</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">reg_aux</span><span class="p">,</span> <span class="n">y_vec</span><span class="p">,</span> <span class="n">x_vec</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NAR&quot;</span><span class="p">:</span>
            <span class="n">reg_aux</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">reg_aux</span><span class="p">,</span> <span class="n">y_vec</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NFIR&quot;</span><span class="p">:</span>
            <span class="n">reg_aux</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">reg_aux</span><span class="p">,</span> <span class="n">x_vec</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;Unrecognized model type. Model type should be NARMAX, NAR or NFIR&quot;</span>
            <span class="p">)</span>

        <span class="n">regressor_code</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">combinations_with_replacement</span><span class="p">(</span><span class="n">reg_aux</span><span class="p">,</span> <span class="n">non_degree</span><span class="p">))</span>

        <span class="n">regressor_code</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">regressor_code</span><span class="p">)</span>
        <span class="n">regressor_code</span> <span class="o">=</span> <span class="n">regressor_code</span><span class="p">[:,</span> <span class="n">regressor_code</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">::</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">regressor_code</span></div>


<div class="viewcode-block" id="HouseHolder"><a class="viewcode-back" href="../../code.html#sysidentpy.narmax_base.HouseHolder">[docs]</a><span class="k">class</span> <span class="nc">HouseHolder</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Householder reflection and transformation.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_house</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform a Householder reflection of vector.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : array-like of shape = number_of_training_samples</span>
<span class="sd">            The respective column of the matrix of regressors in each</span>
<span class="sd">            iteration of ERR function.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        v : array-like of shape = number_of_training_samples</span>
<span class="sd">            The reflection of the array x.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Manuscript: Chen, S., Billings, S. A., &amp; Luo, W. (1989).</span>
<span class="sd">            Orthogonal least squares methods and their application to non-linear system identification.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">u</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">aux_b</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">u</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">/</span> <span class="n">aux_b</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span> <span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">_rowhouse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">RA</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform a row Householder transformation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        RA : array-like of shape = number_of_training_samples</span>
<span class="sd">            The respective column of the matrix of regressors in each</span>
<span class="sd">            iteration of ERR function.</span>
<span class="sd">        v : array-like of shape = number_of_training_samples</span>
<span class="sd">            The reflected vector obtained by using the householder reflection.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        B : array-like of shape = number_of_training_samples</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Manuscript: Chen, S., Billings, S. A., &amp; Luo, W. (1989).</span>
<span class="sd">            Orthogonal least squares methods and their application to</span>
<span class="sd">            non-linear system identification. International Journal of</span>
<span class="sd">            control, 50(5), 1873-1896.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">RA</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">RA</span> <span class="o">=</span> <span class="n">RA</span> <span class="o">+</span> <span class="n">v</span> <span class="o">*</span> <span class="n">w</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">RA</span>
        <span class="k">return</span> <span class="n">B</span></div>


<span class="k">class</span> <span class="nc">ModelInformation</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">_get_index_from_regressor_code</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regressor_code</span><span class="p">,</span> <span class="n">model_code</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the index of user regressor in regressor space.</span>

<span class="sd">        Took from: https://stackoverflow.com/questions/38674027/find-the-row-indexes-of-several-values-in-a-numpy-array/38674038#38674038</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        regressor_code : ndarray of int</span>
<span class="sd">            Matrix codification of all possible regressors.</span>
<span class="sd">        model_code : ndarray of int</span>
<span class="sd">            Model defined by the user to simulate.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        model_index : ndarray of int</span>
<span class="sd">            Index of model code in the regressor space.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="n">regressor_code</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">model_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">in1d</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">ravel_multi_index</span><span class="p">(</span><span class="n">regressor_code</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dims</span><span class="p">),</span>
                <span class="n">np</span><span class="o">.</span><span class="n">ravel_multi_index</span><span class="p">(</span><span class="n">model_code</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dims</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">model_index</span>

    <span class="k">def</span> <span class="nf">_list_output_regressor_code</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_code</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a flattened array of output regressors.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_code : ndarray of int</span>
<span class="sd">            Model defined by the user to simulate.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        model_code : ndarray of int</span>
<span class="sd">            Flattened list of output regressors.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">regressor_code</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">code</span> <span class="k">for</span> <span class="n">code</span> <span class="ow">in</span> <span class="n">model_code</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="n">code</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">code</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">regressor_code</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_list_input_regressor_code</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_code</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a flattened array of input regressors.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_code : ndarray of int</span>
<span class="sd">            Model defined by the user to simulate.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        model_code : ndarray of int</span>
<span class="sd">            Flattened list of output regressors.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">regressor_code</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">code</span> <span class="k">for</span> <span class="n">code</span> <span class="ow">in</span> <span class="n">model_code</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="n">code</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">code</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">regressor_code</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_lag_from_regressor_code</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regressors</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the maximum lag from array of regressors.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        regressors : ndarray of int</span>
<span class="sd">            Flattened list of input or output regressors.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        max_lag : int</span>
<span class="sd">            Maximum lag of list of regressors.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">lag_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">regressors</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;str&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="mi">2</span><span class="p">:]))]</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lag_list</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">lag_list</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">_get_max_lag_from_model_code</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_code</span><span class="p">):</span>
        <span class="n">xlag_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_list_input_regressor_code</span><span class="p">(</span><span class="n">model_code</span><span class="p">)</span>
        <span class="n">ylag_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_list_output_regressor_code</span><span class="p">(</span><span class="n">model_code</span><span class="p">)</span>
        <span class="n">xlag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lag_from_regressor_code</span><span class="p">(</span><span class="n">xlag_code</span><span class="p">)</span>
        <span class="n">ylag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lag_from_regressor_code</span><span class="p">(</span><span class="n">ylag_code</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">xlag</span><span class="p">,</span> <span class="n">ylag</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_max_lag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ylag</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">xlag</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the max lag defined by the user.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ylag : int</span>
<span class="sd">            The maximum lag of output regressors.</span>
<span class="sd">        xlag : int</span>
<span class="sd">            The maximum lag of input regressors.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        max_lag = int</span>
<span class="sd">            The max lag value defined by the user.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ny</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">([[</span><span class="n">ylag</span><span class="p">]])))</span>
        <span class="n">nx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">([[</span><span class="n">xlag</span><span class="p">]])))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="n">ny</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">nx</span><span class="p">)])</span>


<div class="viewcode-block" id="InformationMatrix"><a class="viewcode-back" href="../../code.html#sysidentpy.narmax_base.InformationMatrix">[docs]</a><span class="k">class</span> <span class="nc">InformationMatrix</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Class for methods regarding preprocessing of columns&quot;&quot;&quot;</span>

<div class="viewcode-block" id="InformationMatrix.shift_column"><a class="viewcode-back" href="../../code.html#sysidentpy.narmax_base.InformationMatrix.shift_column">[docs]</a>    <span class="k">def</span> <span class="nf">shift_column</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">col_to_shift</span><span class="p">,</span> <span class="n">lag</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Shift values based on a lag.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        col_to_shift : array-like of shape = n_samples</span>
<span class="sd">            The samples of the input or output.</span>
<span class="sd">        lag : int</span>
<span class="sd">            The respective lag of the regressor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tmp_column : array-like of shape = n_samples</span>
<span class="sd">            The shifted array of the input or output.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; y = [1, 2, 3, 4, 5]</span>
<span class="sd">        &gt;&gt;&gt; shift_column(y, 1)</span>
<span class="sd">        [0, 1, 2, 3, 4]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">col_to_shift</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">tmp_column</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">aux</span> <span class="o">=</span> <span class="n">col_to_shift</span><span class="p">[</span><span class="mi">0</span> <span class="p">:</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">lag</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># aux = np.reshape(aux, (len(aux), 1))</span>
        <span class="n">tmp_column</span><span class="p">[</span><span class="n">lag</span><span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">aux</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">tmp_column</span></div>

    <span class="k">def</span> <span class="nf">_process_xlag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">xlag</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create the list of lags to be used for the inputs</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like</span>
<span class="sd">            Input data used on training phase.</span>
<span class="sd">        xlag : int</span>
<span class="sd">            The maximum lag of input regressors.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x_lag : ndarray of int</span>
<span class="sd">            The range of lags according to user definition.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_inputs</span> <span class="o">=</span> <span class="n">_num_features</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xlag</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n_inputs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;If n_inputs &gt; 1, xlag must be a nested list. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">xlag</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">xlag</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">xlag</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">xlag</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">n_inputs</span><span class="p">,</span> <span class="n">xlag</span>

    <span class="k">def</span> <span class="nf">_process_ylag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ylag</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create the list of lags to be used for the outputs</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ylag : int, list</span>
<span class="sd">            The maximum lag of input regressors.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_lag : ndarray of int</span>
<span class="sd">            The range of lags according to user definition.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ylag</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">ylag</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ylag</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ylag</span>

    <span class="k">def</span> <span class="nf">_create_lagged_X</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">xlag</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a lagged matrix of inputs without combinations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like</span>
<span class="sd">            Input data used on training phase.</span>
<span class="sd">        xlag : int</span>
<span class="sd">            The maximum lag of input regressors.</span>
<span class="sd">        n_inputs : int</span>
<span class="sd">            Number of input variables.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        x_lagged : ndarray of floats</span>
<span class="sd">            A lagged input matrix formed by the input regressors</span>
<span class="sd">            without combinations.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">n_inputs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x_lagged</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
                <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">shift_column</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lag</span><span class="p">)</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="n">xlag</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_lagged</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># just to stack other columns</span>
            <span class="c1"># if user input a nested list like [[1, 2], 4], the following</span>
            <span class="c1"># line convert it to [[1, 2], [4]].</span>
            <span class="c1"># Remember, for multiple inputs all lags must be entered explicitly</span>
            <span class="n">xlag</span> <span class="o">=</span> <span class="p">[[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">xlag</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">):</span>
                <span class="n">x_lagged_col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
                    <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">shift_column</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">col</span><span class="p">],</span> <span class="n">lag</span><span class="p">)</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="n">xlag</span><span class="p">[</span><span class="n">col</span><span class="p">]]</span>
                <span class="p">)</span>
                <span class="n">x_lagged</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">x_lagged</span><span class="p">,</span> <span class="n">x_lagged_col</span><span class="p">])</span>

            <span class="n">x_lagged</span> <span class="o">=</span> <span class="n">x_lagged</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>  <span class="c1"># remove the column of 0 created above</span>

        <span class="k">return</span> <span class="n">x_lagged</span>

    <span class="k">def</span> <span class="nf">_create_lagged_y</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ylag</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a lagged matrix of the output without combinations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array-like</span>
<span class="sd">            Output data used on training phase.</span>
<span class="sd">        ylag : int</span>
<span class="sd">            The maximum lag of output regressors.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_lagged : ndarray of floats</span>
<span class="sd">            A lagged input matrix formed by the output regressors</span>
<span class="sd">            without combinations.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y_lagged</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">shift_column</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lag</span><span class="p">)</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="n">ylag</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">y_lagged</span>

<div class="viewcode-block" id="InformationMatrix.initial_lagged_matrix"><a class="viewcode-back" href="../../code.html#sysidentpy.narmax_base.InformationMatrix.initial_lagged_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">initial_lagged_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xlag</span><span class="p">,</span> <span class="n">ylag</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Build a lagged matrix concerning each lag for each column.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : ndarray of int</span>
<span class="sd">            The model code representation.</span>
<span class="sd">        y : array-like</span>
<span class="sd">            Target data used on training phase.</span>
<span class="sd">        X : array-like</span>
<span class="sd">            Input data used on training phase.</span>
<span class="sd">        ylag : int</span>
<span class="sd">            The maximum lag of output regressors.</span>
<span class="sd">        xlag : int</span>
<span class="sd">            The maximum lag of input regressors.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        lagged_data : ndarray of floats</span>
<span class="sd">            The lagged matrix built in respect with each lag and column.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Let X and y be the input and output values of shape Nx1.</span>
<span class="sd">        If the chosen lags are 2 for both input and output</span>
<span class="sd">        the initial lagged matrix will be formed by Y[k-1], Y[k-2],</span>
<span class="sd">        X[k-1], and X[k-2].</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_inputs</span><span class="p">,</span> <span class="n">xlag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_xlag</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">xlag</span><span class="p">)</span>
        <span class="n">ylag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_ylag</span><span class="p">(</span><span class="n">ylag</span><span class="p">)</span>
        <span class="n">x_lagged</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_lagged_X</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">xlag</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">)</span>
        <span class="n">y_lagged</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_lagged_y</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">ylag</span><span class="p">)</span>
        <span class="n">lagged_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y_lagged</span><span class="p">,</span> <span class="n">x_lagged</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lagged_data</span></div>

<div class="viewcode-block" id="InformationMatrix.build_output_matrix"><a class="viewcode-back" href="../../code.html#sysidentpy.narmax_base.InformationMatrix.build_output_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">build_output_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ylag</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Build the information matrix of output values.</span>

<span class="sd">        Each columns of the information matrix represents a candidate</span>
<span class="sd">        regressor. The set of candidate regressors are based on xlag,</span>
<span class="sd">        ylag, and non_degree entered by the user.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : ndarray of int</span>
<span class="sd">            The model code representation.</span>
<span class="sd">        y : array-like</span>
<span class="sd">            Target data used on training phase.</span>
<span class="sd">        ylag : int</span>
<span class="sd">            The maximum lag of output regressors.</span>
<span class="sd">        non_degree : int</span>
<span class="sd">            The desired maximum nonlinearity degree.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        lagged_data = ndarray of floats</span>
<span class="sd">            The lagged matrix built in respect with each lag and column.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generate a lagged data which each column is a input or output</span>
        <span class="c1"># related to its respective lags. With this approach we can create</span>
        <span class="c1"># the information matrix by using all possible combination of</span>
        <span class="c1"># the columns as a product in the iterations</span>
        <span class="n">ylag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_ylag</span><span class="p">(</span><span class="n">ylag</span><span class="o">=</span><span class="n">ylag</span><span class="p">)</span>
        <span class="n">y_lagged</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_lagged_y</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">ylag</span><span class="p">)</span>
        <span class="n">constant</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">y_lagged</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">constant</span><span class="p">,</span> <span class="n">y_lagged</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span></div>

<div class="viewcode-block" id="InformationMatrix.build_input_matrix"><a class="viewcode-back" href="../../code.html#sysidentpy.narmax_base.InformationMatrix.build_input_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">build_input_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">xlag</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Build the information matrix of input values.</span>

<span class="sd">        Each columns of the information matrix represents a candidate</span>
<span class="sd">        regressor. The set of candidate regressors are based on xlag,</span>
<span class="sd">        ylag, and non_degree entered by the user.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : ndarray of int</span>
<span class="sd">            The model code representation.</span>
<span class="sd">        X : array-like</span>
<span class="sd">            Input data used on training phase.</span>
<span class="sd">        xlag : int</span>
<span class="sd">            The maximum lag of input regressors.</span>
<span class="sd">        non_degree : int</span>
<span class="sd">            The desired maximum nonlinearity degree.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        lagged_data = ndarray of floats</span>
<span class="sd">            The lagged matrix built in respect with each lag and column.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generate a lagged data which each column is a input or output</span>
        <span class="c1"># related to its respective lags. With this approach we can create</span>
        <span class="c1"># the information matrix by using all possible combination of</span>
        <span class="c1"># the columns as a product in the iterations</span>

        <span class="n">n_inputs</span><span class="p">,</span> <span class="n">xlag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_xlag</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">xlag</span><span class="p">)</span>
        <span class="n">x_lagged</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_lagged_X</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">xlag</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">)</span>
        <span class="n">constant</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">x_lagged</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">constant</span><span class="p">,</span> <span class="n">x_lagged</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span></div>

<div class="viewcode-block" id="InformationMatrix.build_input_output_matrix"><a class="viewcode-back" href="../../code.html#sysidentpy.narmax_base.InformationMatrix.build_input_output_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">build_input_output_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xlag</span><span class="p">,</span> <span class="n">ylag</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Build the information matrix.</span>

<span class="sd">        Each columns of the information matrix represents a candidate</span>
<span class="sd">        regressor. The set of candidate regressors are based on xlag,</span>
<span class="sd">        ylag, and non_degree entered by the user.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : ndarray of int</span>
<span class="sd">            The model code representation.</span>
<span class="sd">        y : array-like</span>
<span class="sd">            Target data used on training phase.</span>
<span class="sd">        X : array-like</span>
<span class="sd">            Input data used on training phase.</span>
<span class="sd">        ylag : int</span>
<span class="sd">            The maximum lag of output regressors.</span>
<span class="sd">        xlag : int</span>
<span class="sd">            The maximum lag of input regressors.</span>
<span class="sd">        non_degree : int</span>
<span class="sd">            The desired maximum nonlinearity degree.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        lagged_data = ndarray of floats</span>
<span class="sd">            The lagged matrix built in respect with each lag and column.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generate a lagged data which each column is a input or output</span>
        <span class="c1"># related to its respective lags. With this approach we can create</span>
        <span class="c1"># the information matrix by using all possible combination of</span>
        <span class="c1"># the columns as a product in the iterations</span>
        <span class="n">lagged_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_lagged_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xlag</span><span class="o">=</span><span class="n">xlag</span><span class="p">,</span> <span class="n">ylag</span><span class="o">=</span><span class="n">ylag</span><span class="p">)</span>
        <span class="n">constant</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">lagged_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">constant</span><span class="p">,</span> <span class="n">lagged_data</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span></div></div>


<span class="k">class</span> <span class="nc">ModelPrediction</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">steps_ahead</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the predicted values given an input.</span>

<span class="sd">        The predict function allows a friendly usage by the user.</span>
<span class="sd">        Given a previously trained model, predict values given</span>
<span class="sd">        a new set of data.</span>

<span class="sd">        This method accept y values mainly for prediction n-steps ahead</span>
<span class="sd">        (to be implemented in the future)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray of floats</span>
<span class="sd">            The input data to be used in the prediction process.</span>
<span class="sd">        y : ndarray of floats</span>
<span class="sd">            The output data to be used in the prediction process.</span>
<span class="sd">        steps_ahead = int (default = None)</span>
<span class="sd">            The forecast horizon.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yhat : ndarray of floats</span>
<span class="sd">            The predicted values of the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_function</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;Polynomial&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">steps_ahead</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">steps_ahead</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_one_step_ahead_prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_check_positive_int</span><span class="p">(</span><span class="n">steps_ahead</span><span class="p">,</span> <span class="s2">&quot;steps_ahead&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_step_ahead_prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">steps_ahead</span><span class="o">=</span><span class="n">steps_ahead</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">steps_ahead</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_basis_function_predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">steps_ahead</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_one_step_ahead_prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_code2exponents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">code</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert regressor code to exponents array.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        code : 1D-array of int</span>
<span class="sd">            Codification of one regressor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">regressors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">code</span><span class="p">)))</span>
        <span class="n">regressors_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">regressors</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span><span class="p">))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">exponents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="n">elements</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">regressors</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="mi">0</span><span class="p">)[</span>
                <span class="p">(</span><span class="n">regressors</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span> <span class="o">+</span> <span class="mi">2</span><span class="p">):</span>
                <span class="n">base_exponents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">elements</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                        <span class="n">regressor_code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="mi">1000</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>
                        <span class="n">base_exponents</span><span class="p">[</span><span class="o">-</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">regressors_count</span><span class="p">[</span><span class="n">regressor_code</span><span class="p">]</span>
                    <span class="n">exponents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">exponents</span><span class="p">,</span> <span class="n">base_exponents</span><span class="p">)</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="n">exponents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">exponents</span><span class="p">,</span> <span class="n">base_exponents</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">exponents</span>

    <span class="k">def</span> <span class="nf">_one_step_ahead_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform the 1-step-ahead prediction of a model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array-like of shape = max_lag</span>
<span class="sd">            Initial conditions values of the model</span>
<span class="sd">            to start recursive process.</span>
<span class="sd">        X : ndarray of floats of shape = n_samples</span>
<span class="sd">            Vector with input values to be used in model simulation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yhat : ndarray of floats</span>
<span class="sd">               The 1-step-ahead predicted values of the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NAR&quot;</span><span class="p">:</span>
            <span class="n">lagged_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_output_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ylag</span><span class="p">)</span>
            <span class="c1"># self.max_lag = ModelInformation()._get_max_lag(ylag=self.ylag)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NFIR&quot;</span><span class="p">:</span>
            <span class="n">lagged_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_input_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xlag</span><span class="p">)</span>
            <span class="c1"># self.max_lag = ModelInformation()._get_max_lag(xlag=self.xlag)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NARMAX&quot;</span><span class="p">:</span>
            <span class="c1"># check_X_y(X, y)</span>
            <span class="c1"># self.max_lag = ModelInformation()._get_max_lag(ylag=self.ylag, xlag=self.xlag)</span>
            <span class="n">lagged_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_input_output_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xlag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ylag</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unrecognized model type. The model_type should be NARMAX, NAR or NFIR.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_function</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;Polynomial&quot;</span><span class="p">:</span>
            <span class="n">X_base</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_function</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                <span class="n">lagged_data</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span>
                <span class="n">predefined_regressors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pivv</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">)],</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_base</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_function</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                <span class="n">lagged_data</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span>
                <span class="n">predefined_regressors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pivv</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">)],</span>
            <span class="p">)</span>

        <span class="c1"># piv_final_model = self.pivv[: len(self.final_model)]</span>
        <span class="c1"># X_base = X_base[:, piv_final_model]</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_base</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">yhat</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">yhat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_n_step_ahead_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">steps_ahead</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform the n-steps-ahead prediction of a model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array-like of shape = max_lag</span>
<span class="sd">            Initial conditions values of the model</span>
<span class="sd">            to start recursive process.</span>
<span class="sd">        X : ndarray of floats of shape = n_samples</span>
<span class="sd">            Vector with input values to be used in model simulation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yhat : ndarray of floats</span>
<span class="sd">               The n-steps-ahead predicted values of the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Insufficient initial conditions elements!&quot;</span><span class="p">)</span>

        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">yhat</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">yhat</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">k</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
                <span class="n">steps_ahead</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="n">i</span>  <span class="c1"># predicts the remaining values</span>

            <span class="n">yhat</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_prediction</span><span class="p">(</span>
                <span class="n">X</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span>
            <span class="p">)[</span><span class="o">-</span><span class="n">steps_ahead</span><span class="p">:]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

            <span class="n">i</span> <span class="o">+=</span> <span class="n">steps_ahead</span>

        <span class="n">yhat</span> <span class="o">=</span> <span class="n">yhat</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">yhat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_model_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_initial</span><span class="p">,</span> <span class="n">forecast_horizon</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform the infinity steps-ahead simulation of a model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y_initial : array-like of shape = max_lag</span>
<span class="sd">            Number of initial conditions values of output</span>
<span class="sd">            to start recursive process.</span>
<span class="sd">        X : ndarray of floats of shape = n_samples</span>
<span class="sd">            Vector with input values to be used in model simulation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yhat : ndarray of floats</span>
<span class="sd">               The predicted values of the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;NARMAX&quot;</span><span class="p">,</span> <span class="s2">&quot;NAR&quot;</span><span class="p">]:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_narmax_predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_initial</span><span class="p">,</span> <span class="n">forecast_horizon</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NFIR&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nfir_predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_initial</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;model_type do not exist! Model type must be NARMAX, NAR or NFIR&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_narmax_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_initial</span><span class="p">,</span> <span class="n">forecast_horizon</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_initial</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Insufficient initial conditions elements!&quot;</span><span class="p">)</span>

        <span class="c1"># X = X.reshape(-1, self._n_inputs)</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">forecast_horizon</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">forecast_horizon</span> <span class="o">=</span> <span class="n">forecast_horizon</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NAR&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">y_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">forecast_horizon</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">y_output</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">y_output</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_initial</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">model_exponents</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_code2exponents</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">]</span>
        <span class="n">raw_regressor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_exponents</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="n">forecast_horizon</span><span class="p">):</span>
            <span class="n">init</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">final</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
            <span class="n">k</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">)</span>
            <span class="n">raw_regressor</span><span class="p">[:</span><span class="n">final</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_output</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">i</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span><span class="p">):</span>
                <span class="n">init</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
                <span class="n">final</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
                <span class="n">raw_regressor</span><span class="p">[</span><span class="n">init</span><span class="p">:</span><span class="n">final</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>

            <span class="n">regressor_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_exponents</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_exponents</span><span class="p">)):</span>
                <span class="n">regressor_value</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">raw_regressor</span><span class="p">,</span> <span class="n">model_exponents</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="p">)</span>

            <span class="n">y_output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">regressor_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">y_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_nfir_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_initial</span><span class="p">):</span>
        <span class="n">y_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">y_output</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">y_output</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_initial</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span><span class="p">)</span>
        <span class="n">model_exponents</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_code2exponents</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">]</span>
        <span class="n">raw_regressor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_exponents</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">init</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">final</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
            <span class="n">k</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span><span class="p">):</span>
                <span class="n">raw_regressor</span><span class="p">[</span><span class="n">init</span><span class="p">:</span><span class="n">final</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">init</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
                <span class="n">final</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>

            <span class="n">regressor_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_exponents</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_exponents</span><span class="p">)):</span>
                <span class="n">regressor_value</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">raw_regressor</span><span class="p">,</span> <span class="n">model_exponents</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="p">)</span>

            <span class="n">y_output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">regressor_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">y_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_basis_function_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_initial</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">forecast_horizon</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">forecast_horizon</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">forecast_horizon</span> <span class="o">=</span> <span class="n">forecast_horizon</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NAR&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">forecast_horizon</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">yhat</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">yhat</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_initial</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Discard unnecessary initial values</span>
        <span class="c1"># yhat[0:self.max_lag] = y_initial[0:self.max_lag]</span>
        <span class="n">analyzed_elements_number</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">forecast_horizon</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NARMAX&quot;</span><span class="p">:</span>
                <span class="n">lagged_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_input_output_matrix</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">analyzed_elements_number</span><span class="p">],</span>
                    <span class="n">yhat</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">analyzed_elements_number</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">xlag</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ylag</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NAR&quot;</span><span class="p">:</span>
                <span class="n">lagged_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_output_matrix</span><span class="p">(</span>
                    <span class="n">yhat</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">analyzed_elements_number</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">ylag</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NFIR&quot;</span><span class="p">:</span>
                <span class="n">lagged_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_input_matrix</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">analyzed_elements_number</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">xlag</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Unrecognized model type. The model_type should be NARMAX, NAR or NFIR.&quot;</span>
                <span class="p">)</span>

            <span class="n">X_tmp</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_function</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
                <span class="n">lagged_data</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span>
                <span class="n">predefined_regressors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pivv</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">)],</span>
            <span class="p">)</span>

            <span class="n">a</span> <span class="o">=</span> <span class="n">X_tmp</span> <span class="o">@</span> <span class="n">theta</span>
            <span class="n">yhat</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">yhat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">basis_function_n_step_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">steps_ahead</span><span class="p">,</span> <span class="n">forecast_horizon</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform the n-steps-ahead prediction of a model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array-like of shape = max_lag</span>
<span class="sd">            Initial conditions values of the model</span>
<span class="sd">            to start recursive process.</span>
<span class="sd">        X : ndarray of floats of shape = n_samples</span>
<span class="sd">            Vector with input values to be used in model simulation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yhat : ndarray of floats</span>
<span class="sd">               The n-steps-ahead predicted values of the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Insufficient initial conditions elements!&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">forecast_horizon</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">forecast_horizon</span> <span class="o">=</span> <span class="n">forecast_horizon</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>

        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">forecast_horizon</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">yhat</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">yhat</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Discard unnecessary initial values</span>
        <span class="n">analyzed_elements_number</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>

        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">k</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
                <span class="n">steps_ahead</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="n">i</span>  <span class="c1"># predicts the remaining values</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NARMAX&quot;</span><span class="p">:</span>
                <span class="n">yhat</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_basis_function_predict</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span>
                <span class="p">)[</span><span class="o">-</span><span class="n">steps_ahead</span><span class="p">:]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NAR&quot;</span><span class="p">:</span>
                <span class="n">yhat</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_basis_function_predict</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">y_initial</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span>
                    <span class="n">theta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                    <span class="n">forecast_horizon</span><span class="o">=</span><span class="n">forecast_horizon</span><span class="p">,</span>
                <span class="p">)[</span><span class="o">-</span><span class="n">forecast_horizon</span> <span class="p">:</span> <span class="o">-</span><span class="n">forecast_horizon</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NFIR&quot;</span><span class="p">:</span>
                <span class="n">yhat</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_basis_function_predict</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span>
                    <span class="n">y_initial</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span>
                    <span class="n">theta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                <span class="p">)[</span><span class="o">-</span><span class="n">steps_ahead</span><span class="p">:]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Unrecognized model type. The model_type should be NARMAX, NAR or NFIR.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># yhat[i : i + steps_ahead] = self._basis_function_predict(</span>
            <span class="c1">#     X[k : i + steps_ahead], y[k : i + steps_ahead], self.theta</span>
            <span class="c1"># )[-steps_ahead:].ravel()</span>

            <span class="n">i</span> <span class="o">+=</span> <span class="n">steps_ahead</span>

        <span class="c1"># yhat = yhat.ravel()</span>
        <span class="k">return</span> <span class="n">yhat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_basis_function_n_steps_horizon</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">steps_ahead</span><span class="p">,</span> <span class="n">forecast_horizon</span><span class="p">):</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">forecast_horizon</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">yhat</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">yhat</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Discard unnecessary initial values</span>
        <span class="n">analyzed_elements_number</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>

        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">k</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
                <span class="n">steps_ahead</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="n">i</span>  <span class="c1"># predicts the remaining values</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NARMAX&quot;</span><span class="p">:</span>
                <span class="n">yhat</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_basis_function_predict</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span>
                <span class="p">)[</span><span class="o">-</span><span class="n">forecast_horizon</span> <span class="p">:</span> <span class="o">-</span><span class="n">forecast_horizon</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NAR&quot;</span><span class="p">:</span>
                <span class="n">yhat</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_basis_function_predict</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">y_initial</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span>
                    <span class="n">theta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                    <span class="n">forecast_horizon</span><span class="o">=</span><span class="n">forecast_horizon</span><span class="p">,</span>
                <span class="p">)[</span><span class="o">-</span><span class="n">forecast_horizon</span> <span class="p">:</span> <span class="o">-</span><span class="n">forecast_horizon</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;NFIR&quot;</span><span class="p">:</span>
                <span class="n">yhat</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_basis_function_predict</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span>
                    <span class="n">y_initial</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">k</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">],</span>
                    <span class="n">theta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                <span class="p">)[</span><span class="o">-</span><span class="n">forecast_horizon</span> <span class="p">:</span> <span class="o">-</span><span class="n">forecast_horizon</span> <span class="o">+</span> <span class="n">steps_ahead</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Unrecognized model type. The model_type should be NARMAX, NAR or NFIR.&quot;</span>
                <span class="p">)</span>

            <span class="c1"># yhat[i : i + steps_ahead] = self._basis_function_predict(</span>
            <span class="c1">#     X[k : i + steps_ahead], y[k : i + steps_ahead], self.theta</span>
            <span class="c1"># )[-steps_ahead:].ravel()</span>

            <span class="n">i</span> <span class="o">+=</span> <span class="n">steps_ahead</span>

        <span class="n">yhat</span> <span class="o">=</span> <span class="n">yhat</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">yhat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Wilson Rocha, Luan Pascoal, Samuel Oliveira, Samir Martins<br/>
    
        &copy; Copyright 2020, Wilson Rocha, Luan Pascoal, Samuel Oliveira, Samir Martins.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>